[{"content":"REST API？ REST API 是当今最常见的 Web 接口形式之一 ，在确保客户端和服务器之间的顺利通信方面发挥了重要作用。 你可以把客户端看作前端，把服务器看作后端。 客户端（前端）和服务器（后端）之间的通信通常不是直接的。因此，我们使用 API（应用编程接口），作为客户端和服务器之间的中介。 因为 API 在这种 client–server 通信中起着至关重要的作用，所以我们在设计 API 时应该遵循最佳实践。这有助于开发人员更好地维护和使用它们。 本篇通过 REST API 时可以遵循的一些最佳实践。这将帮助创建高效，安全，易于使用和维护的 API。\n1.什么是 REST API？ REST 是 Representational State Transfer 的缩写。它是由 Roy Fielding 博士在 2000 年他的博士论文中提出一种软件架构风格，用于指导网络应用的设计和开发，使得 Web API（网络应用编程接口）更加简单、灵活、可扩展和易于理解。 任何遵循 REST 设计原则的 API 都被称为 RESTful API。 简单地说，REST API 是两台计算机通过 HTTP（超文本传输协议）进行通信的媒介，与客户端和服务器的通信方式相同。 REST API 使用 URL 唯一标识和定位 RESTful 服务中的资源，一个完整的 URL 结构如下： 2.REST API 设计建议 1. 用名词表示资源 当你设计一个 REST API 时，端点应该使用名词而非动词。 这是因为 HTTP 方法已经以动词形式执行基本的 CRUD（创建、读取、更新、删除）操作。 GET、POST、PUT、PATCH 和 DELETE 是最常见的 HTTP 动词。还有其他非 HTTP 标准动词，如 COPY、PURGE、LINK、UNLINK 等等。 因此，举例来说，一个端点不应该是这样的：\nhttps://mysite.com/getPosts https://mysite.com/createPost 它应该是这样的：\nhttps://mysite.com/posts 2. 用复数名词表示集合 如果 URL 表示的资源是一个集合应该使用复数名词。 如果你有一个像 https://mysite.com/post/123 这样的端点，用 DELETE 请求删除一个帖子，或用 PUT 或 PATCH 更新一个帖子，可能是可以的，但它没有告诉用户在这个集合中可能还有一些其他帖子。这就是为什么你的集合应该使用复数的名词。 所以，不应该是 https://mysite.com/post/123，而是 https://mysite.com/posts/123。\n3.端点使用嵌套显示关系 很多时候，不同的端点相互联系，所以你应该对它们进行嵌套，这样更容易理解它们。 例如，对于一个多用户博客平台，不同的帖子可能是由不同的作者写的，所以在这种情况下，像 https://mysite.com/posts/author 这样的端点会成为一个有效的嵌套。 同样地，帖子可能有各自的评论，所以要检索评论，可以使用 https://mysite.com/posts/{postId}/comments 这样的端点。 你应该避免超过 3 层的嵌套，因为这可能使 API 不那么优雅，降低可读性。\n4. 用 HTTP 方法操作资源 使用 URL 指定你要用的资源。使用 HTTP 方法来指定怎么处理这个资源。使用五种 HTTP 方法 POST，GET，PUT/PATCH，DELETE 可以提供 CRUD 功能（创建，获取，更新，删除）。 除了 POST 其他请求都具备幂等性（多次请求的效果相同）。需要注意的是 POST 和 PUT 最大的区别就是幂等性，所以 PUT 也可以用于创建操作，只要在创建前就可以确定资源的 ID。\n获取：使用 GET 方法获取资源。GET 请求从不改变资源的状态。无副作用。GET 是幂等的。GET 具有只读的含义。因此，你可以完美的使用缓存。 创建：使用 POST 创建新的资源（非幂等）。 更新：使用 PUT 更新整个资源，PATCH 更新资源部分信息。PUT 和 PATCH 都是幂等的。 删除：使用 DELETE 删除现有资源（幂等）。 简而言之，你应该让 HTTP 动词来处理端点的工作。因此，GET 将检索资源，POST 将创建资源，PUT 将更新整个资源，DELETE 将删除资源，PATCH 更新资源的局部数据。 5. 使用 JSON 作为发送和接收数据的格式 在过去，接受和响应 API 请求主要是通过 XML 甚至 HTML 完成的。但如今，JSON（JavaScript Object Notation）已经在很大程度上成为发送和接收 API 数据的事实格式。 以 XML 为例，对数据进行解码和编码往往有点麻烦，所以 XML 不再受到框架的广泛支持。 例如，JavaScript 有一个内置的方法来通过 fetch API 解析 JSON 数据，因为 JSON 主要是为它而生成的。但是如果你使用任何其他编程语言，如 Python 或 PHP，它们现在也都有解析和操作 JSON 数据的方法。 例如，Python 提供json.load() 和 json.dumps()来处理 JSON 数据。 为了确保客户端正确地解释 JSON 数据，你应该在发出请求时将响应头中的 Content-Type 类型设置为 application/json。 另一方面，对于服务器端的框架，许多框架会自动设置 Content-Type。例如，Express 现在有 express.json() 中间件来实现这一目的。body-parser NPM 包也仍然适用于同一目的。 6. JSON 键命名使用 camelCase 风格 JSON 键命名风格没有统一的标准。 但是最常见有两种，下划线风格的 snake_case 和小驼峰 camelCase。 不同的语言，不同的公司，不同的开源项目均不相同，团队统一即可。 鉴于 REST API 常被 Java 和 JS 实现的客户端调用，且 Java 和 JS 常用 camelCase 来命名 JSON。此外 Google JSON Style Guide 也使用 camelCase，所以推荐使用 camelCase 格式命名 JSON 键。 7. 使用统一的回包格式，将实际数据包装在 data 字段中 接口回包时我们应该使用统一的回包格式，将实际数据包装在 data 字段中。\n{ \u0026#34;code\u0026#34;: 0, \u0026#34;msg\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;data\u0026#34;:{} } 比如查询某个帖子详情 GET https://mysite.com/posts/{id}回包内容可以是：\n{ \u0026#34;code\u0026#34;: 0, \u0026#34;msg\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;post\u0026#34;: {\u0026#34;id\u0026#34;:1, \u0026#34;content\u0026#34;:\u0026#34;xxx\u0026#34;} } } 其中 code 为 0 表示成功，非 0 表示失败，并在 msg 中记录详细的错误信息。 分页接口回包 data 结构包含 total 总记录数。 比如分页拉取帖子详情。\n{ \u0026#34;code\u0026#34;: 0, \u0026#34;msg\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;total\u0026#34;: 100, \u0026#34;posts\u0026#34;: [ {\u0026#34;id\u0026#34;:1, \u0026#34;content\u0026#34;:\u0026#34;xxx\u0026#34;}, {\u0026#34;id\u0026#34;:2, \u0026#34;content\u0026#34;:\u0026#34;xxx\u0026#34;}, {\u0026#34;id\u0026#34;:3, \u0026#34;content\u0026#34;:\u0026#34;xxx\u0026#34;} ] } } 8. 非资源请求用动词 有时 API 调用并不涉及资源，比如计算、翻译或转换等。\nGET /translate?from=de\u0026amp;to=en\u0026amp;text=Hallo GET /calculate?param1=23¶m2=432 在这种情况下，API 响应不会返回任何资源，而是执行一个操作并将结果返回给客户端。因此，我们应该在 URL 中使用动词而不是名词，来清楚地区分资源请求和非资源请求。\n9. 分页返回数据 有时 API 获取的数据可能非常大，一次性返回所有数据是一个糟糕的做法，因为这会带来严重的性能问题和不必要的带宽浪费。 所以，我们应该分页返回数据。 分页返回，常见的实现方式是在 API 参数中提供 page 和 size（offset 和 limit）或 after_id 和 limit。 page 与 size 适合数据总量小的浅分页查询，after_id 和 limit 适合数据总量大的深分页查询。\n// 浅分页 GET https://mysite.com/posts?page=PAGE\u0026amp;size=SIZE // 深分页 GET https://mysite.com/posts?after_id=AFTER_ID\u0026amp;limit=LIMIT 10. 考虑特定资源搜索和跨资源搜索 * 提供对特定资源的搜索很容易。只需使用相应的资源集合 URL，并将搜索字符串附加到查询参数中即可。 ```` GET /employees?query ```` * 如果要对所有资源提供全局搜索，则需要用其他方法。前文提到，对于非资源请求 URL，使用动词而非名词。因此，您的搜索网址可能如下所示： ```` GET /search?query=Paul // 返回 employees, customers, suppliers 等等。 ```` 11. URL Path 使用连字符分隔单词 一个合法的 HTTP URL 组成格式如下：\nhttp(s)://\u0026lt;host\u0026gt;:\u0026lt;port\u0026gt;/\u0026lt;path\u0026gt;?\u0026lt;query\u0026gt;#\u0026lt;frag\u0026gt; Path 如何分隔单词？REST API 的最佳实践是使用连字符（hyphen），而不是下划线（underscore）或驼峰（camelcase）。这是来自 Mark Masse 的《REST API Design Rulebook》的建议。 此外，搜索引擎也更喜欢使用连字符来分隔单词，使用连字符分隔单词，它们让搜索引擎更准确地理解 URL 中的单词和短语，这样搜索引擎就可以索引单个单词，有助于 SEO，很容易检索到这个 URL，排名靠前。 许多著名公司都遵循该实践方式，如 Stack Overflow。 如一个使用连字符的 REST API URL 可能如下所示： https://api.example.com/users/john-doe 而使用下划线的 URL 则可能如下所示：\nhttps://api.example.com/users/john_doe 虽然两者在技术上都是有效的 URL，但前者更符合 REST API 的最佳实践。\n12. URL Query 使用下划线分隔单词 查询字符串是 URL 的组成部分。URL 规范规定查询字符串的不同参数使用与号（\u0026amp;）分隔，参数名与值使用等号（=）分隔。 当我们在 URL Query 中命名参数名称与值时，建议使用下划线。 如一个使用下划线的查询参数可能如下所示：\nfirst_name=john\u0026amp;last_name=doe 而使用连字符的查询参数则可能如下所示：\nfirst-name=john\u0026amp;last-name=doe 虽然在技术上两者都是有效的，但使用下划线表示被连接的不同单词是一个整体，更符合 REST API 的最佳实践，并且更容易读写和阅读。 当然这不是绝对的，对于一些复杂的情况，下划线和连字符可以混用。\nname_birthdate=john_doe-2023_06_09 其中 john_doe 表示一个整体，2023_06_09 表示一个整体，二者通过连字符分隔。\n13. 使用 HTTP 状态码 你应该在对你的 API 请求的响应中始终使用常规的 HTTP 状态代码。这将帮助你的用户知道发生了什么——请求是否成功，或者是否失败，或者其他情况。 下面的表格显示了不同的 HTTP 状态代码范围和它们的含义： HTTP 状态码速查表 类别 状态码 状态描述 (Reason Phrase) 含义与应用场景 1xx 100 Continue 继续：服务器已收到请求头，客户端应继续发送请求体。 信息 101 Switching Protocols 切换协议：升级为 WebSocket 等协议。 \u0026mdash; \u0026mdash; \u0026mdash; \u0026mdash; 2xx 200 OK 成功：请求已正常处理。 成功 201 Created 已创建：成功创建了新资源（如 POST 创建用户）。 204 No Content 无内容：处理成功但无需返回数据（如删除资源）。 206 Partial Content 部分内容：范围请求成功（如断点续传、分段下载）。 \u0026mdash; \u0026mdash; \u0026mdash; \u0026mdash; 3xx 301 Moved Permanently 永久重定向：资源已永久移动到新 URL。 重定向 302 Found 临时重定向：资源临时移动，SEO 不会更新权重。 304 Not Modified 未修改：使用本地缓存，不返回资源。 \u0026mdash; \u0026mdash; \u0026mdash; \u0026mdash; 4xx 400 Bad Request 错误请求：语义有误或参数错误，服务器无法理解。 客户端 401 Unauthorized 未授权：需要进行身份验证。 错误 403 Forbidden 禁止：服务器拒绝执行（通常是权限不够）。 404 Not Found 未找到：服务器上找不到请求的资源。 405 Method Not Allowed 方法禁用：如接口只支持 GET，你用了 POST。 429 Too Many Requests 请求过多：触发了 API 的频率限制。 \u0026mdash; \u0026mdash; \u0026mdash; \u0026mdash; 5xx 500 Internal Server Error 服务器内部错误：代码报错、数据库挂了等。 服务器 502 Bad Gateway 网关错误：Nginx 转发到了一个失效的后端服务。 错误 503 Service Unavailable 服务不可用：服务器超载或正在维护。 504 Gateway Timeout 网关超时：后端处理太慢，导致网关等待超时。 常用: 200 OK: 一切正常。 301 vs 302: 永久重定向（SEO 权重转移） vs 临时重定向。 403 vs 404: 拒绝访问（有资源但没权限） vs 找不到资源。 500: 代码写错了，或者服务器炸了。 502 vs 504: 网关收到错误响应 vs 网关没收到响应（超时）。 简略: 1 (Informational): 正在响应（信息中转） 2 (Success): 已经成功 3 (Redirection): 需要重定向 4 (Client Error): 是客户端的错 5 (Server Error): 是服务器的错 14. 提供有用的错误消息 除了提供恰当的 HTTP 状态代码外，还应该在 HTTP 响应正文中提供有用且详细的错误描述。 比如GET /mysite.com/posts?category=unknow\u0026amp;page=1\u0026amp;size=10 请求，如果入参有误，应该准确告知调用方。 // 400 Bad Request { \u0026#34;code\u0026#34;: 10000, \u0026#34;msg\u0026#34;:\u0026#34;Invalid category. Valid values are \u0026#39;biz\u0026#39; or \u0026#39;tech\u0026#39;\u0026#34; } 15. 明确版本划分 REST API 应该有不同的版本，因为如果有不兼容和破坏性的更改，版本号将让你能更容易发布 API，且不会破坏用户的应用程序。 划分 API 版本，常见的做法是在 URL Path 中加入版本标识。 /v1/employees /v2/employees 许多科技巨头和个人的 REST API 通常是这样做的，例如 Facebook 与 Spotify 当您以这种方式提供 REST API 时，您不需要强迫客户端迁移到新版本，如果他们不想迁移的话。\n16. 使用 HATEOAS API 的使用者未必知道，URL 是怎么设计的。一个解决方法就是，在响应中给出相关链接，便于下一步操作。这样的话，用户只要记住一个 URL，就可以发现其他的 URL。这种方法叫做 HATEOAS。 HATEOAS 是 Hypermedia As The Engine Of Application State 的缩写，从字面上理解是 “超媒体即是应用状态引擎” 。其原则就是客户端与服务器的交互完全由超媒体动态提供，客户端无需事先了解如何与数据或服务器交互。相反的，在一些 RPC 服务或 Redis、MySQL 等软件，需要事先了解接口定义或特定的交互语法。\n举例来说，GitHub 的 API 都在 api.github.com 这个域名。访问它，就可以得到其他 URL。\n{ ... \u0026#34;feeds_url\u0026#34;: \u0026#34;https://api.github.com/feeds\u0026#34;, \u0026#34;followers_url\u0026#34;: \u0026#34;https://api.github.com/user/followers\u0026#34;, \u0026#34;following_url\u0026#34;: \u0026#34;https://api.github.com/user/following{/target}\u0026#34;, \u0026#34;gists_url\u0026#34;: \u0026#34;https://api.github.com/gists{/gist_id}\u0026#34;, \u0026#34;hub_url\u0026#34;: \u0026#34;https://api.github.com/hub\u0026#34;, ... } 上面的回应中，挑一个 URL 访问，又可以得到别的 URL。对于用户来说，不需要记住 URL 设计，只要从 api.github.com 一步步查找就可以了。\n17. 提供准确的 API 文档 当你创建 REST API 时，你需要帮助用户（消费者）正确学习并了解如何使用它。最好的方法是为 API 提供良好的文档。 文档应包含：\nAPI 的相关端点 端点的示例请求 在几种编程语言中的实现 不同错误的消息列表及其状态代码 你可以用于 API 文档的最常用工具是 Swagger。你也可以使用 Postman 来记录你的 API，这是软件开发中最常见的 API 测试工具。\n18. 使用 TLS 保障安全 TLS（Transport Layer Security）指的是传输层安全协议。这对 REST API 的安全性至关重要。使用 SSL 可以保护你的 API，使其更不容易受到恶意攻击。 TLS 证书不难加载到服务器上，而且大多数情况下在第一年是免费的。即使需要购买，它们也并不昂贵。\n运行在 TLS 上的 REST API 的 URL 与不运行在 TLS 上的 URL 的明显区别是协议 HTTP 中是否包含 s，https://mysite.com/posts 运行在 TLS 上，http://mysite.com/posts 不运行在 TLS 上。\n你还应考虑其他安全措施，比如对请求做身份校验。\n19. 使用统一的错误码 同一个服务的不同 API 或不同系统模块的不同服务的 API 应该使用统一的错误码。 统一的错误码有很多优势。 * 易于维护： 统一的错误码可以使 API 的维护更加简单。当需要调整错误信息或添加新的错误时，只需修改一处错误码定义即可，而无需在整个 API 中查找和修改多处。 * 对调用方友好： 使用统一的错误码可以降低客户端开发的难度。客户端只需关注预定义的错误码，而无需解析和处理不同形式的错误响应。 * 错误诊断和日志记录： 统一的错误码可以帮助开发人员更轻松地诊断 API 中的问题。错误日志中使用统一的错误码可以提供更准确的错误信息，帮助定位和解决问题。 在实际应用中，需要根据具体业务场景来选择合适的错误码策略。错误码的设计应该符合 API 的业务逻辑和语义，同时也需要与客户端开发人员进行充分的沟通和协商。 下面是一些常见的错误。\ncode 说明 10000 入参有误 10001 Token 非法 10002 请求处理超时 10003 记录未找到 10004 DB 写入失败 10005 DB 更新失败 10006 DB 查询失败 10007 DB 删除失败 10008 JSON 序列化失败 10009 JSON 反序列化失败 关于错误码的定义，一般没有固定的规定，不同的系统和应用可能会采用不同的错误码起始值。错误码的起始值通常是根据具体需求和规模来确定的。 比如在大规模的系统中，可能会选择更大的错误码起始值，从 10000、100000 开始，以便在未来可以灵活地添加更多的错误码。\n3.一个文章API设计 一般来说 API 的外在形式无非就是增删改查（当然具体的业务逻辑肯定要复杂得多），而查询又分为详情和列表两种，在 REST 中这就相当于通用的模板。\n例如针对文章（Article）设计 API，那么最基础的 URL 就是这几种：\nGET /articles： 文章列表 GET /articles/{id}：文章详情 POST /articles： 创建文章 PUT /articles/{id}：修改文章 PATCH /articles/{id}：修改文章的部分信息 DELETE /articles/{id}：删除文章 将文章 ID 放在 Path 而不是 Query 中的一个好处是可以表示资源之间的层级关系。 例如文章下面会有评论（Comment）和点赞（Like），这两项资源必然会属于某一篇文章，所以它们的 URL 应该是下面这样的。\nGET /comments/{id}： 获取单个评论 GET /articles/{id}/comments： 某篇文章的评论列表 POST /articles/{id}/comments： 为篇文章创建评论 PUT /comments/{id}： 修改评论 PATCH /comments/{id}： 修改评论的部分信息 DELETE /comments/{id}： 删除评论 这里有一点比较特殊，永远使用可以指向资源最短的 URL，也就是说既然 /comments/{id} 可以指向一条评论了，就不要用 /articles/{id}/comments/{id} 特意指出所属文章了。\nGET\t/articles/{id}/like：查看文章是否被点赞 PUT\t/articles/{id}/like：点赞文章 DELETE /articles/{id}/like：取消点赞 注意，点赞文章我选择了 PUT 而不是 POST，因为我觉得点赞这种行为应该是幂等的，多次操作的结果应该相同。另外，是否点赞可以直接在获取文章详情时返回，而不用单独写一个接口。\n4.REST API常见问题 4.1 批量新增接口如何设计？ 使用复数形式的资源名称来表示批量新增多个资源的操作，这与新增单个的接口存在冲突，不建议使用。在资源路径后添加一个表示批量操作的子路径，含义简洁明了，建议使用。\n// 不推荐 POST /resources // 推荐 POST /resources/batch 4.2 批量查询接口如何设计？ 根据 ID 获取单个资源可以使用如下 URL。\nGET /resources/{id} 如果需要根据 ID 同时删除多个资源，URL 该如何设计呢？ 常见的方式有如下几种。\n第一种：Path 传参。 使用 GET 方法，多个资源 ID 放进 URL Path 中。\nGET /resources/ids/1,2,3... 使用 GET 方法时，将多个资源 ID 放到 Path 中传递，并且在路径中加入 ids 标识和单个 ID 接口区分开来。路径中的资源 ID 更具语义化且更具可读性，建议使用。\n第二种：Query 传参。 使用 GET 方法，用多个资源 ID 放进 URL Query 中。\nGET /resources?ids=1,2,3... 查询参数可以方便地与其他查询参数一起使用，进行过滤、排序和分页等操作。不过将多个 ID 放到 Query 传递，查询参数不够直观，需要在文档中明确指出如何传递多个 ID。\n注意，由于浏览器和服务器一般对 URL 的长度存在限制（没有统一标准上限，一般为 8192 字节），上面两种方式如果操作的资源过多无法实现。从实际来看，一般批量操作时需要为 ID 数设置一个上限，这样便不会触及 URL 的上限。\n第三种：Body 传参。 使用 GET 方法，用多个资源 ID 放进请求体中。\nGET /resources Content-Type: application/json { \u0026#34;ids\u0026#34;:[1,2,3] } 虽然 HTTP 规范允许 GET 请求发送请求体，但大多数 Web 服务器和客户端库在处理 GET 请求时会忽略请求体。也就是说，大多数 Web 服务器和客户端库并不期望在 GET 请求中包含请求体，并且可能会忽略或拒绝处理请求体中的数据。 HTTP/1.1 规范（RFC 7231）中指出：\nA payload within a GET request message has no defined semantics; sending a payload body on a GET request might cause some existing implementations to reject the request.\n也就是说 HTTP/1.1 规范虽然允许 GET 请求发送请求体，但是不建议这么做，因为 GET 请求被定义为获取资源的操作，而不是在请求体中发送数据。\n根据 RESTful 设计准则，对于 GET 请求，也不应将请求参数放在请求体中。GET 请求的查询参数应该直接放在 URL 中，而不是放在请求体中。\n第四种：POST + Body 传参。 使用 POST 方法，将多个 ID 封装在请求体中。请求体可以是 JSON 或其他格式的数据，用于传递多个 ID。\nPOST /resources Content-Type: application/json { \u0026#34;ids\u0026#34;: [1, 2, 3] } 由于 POST 语义上不符合实际的查询动作，所以建议使用 GET 方法。\n3. 批量删除接口如何设计？ 删除单个资源可以在 URL Path 中指定资源 ID。\nDELETE /resources/{id} 如果需要根据 ID 同时删除多个资源，URL 该如何设计呢？ 常见的方式有如下几种。\n第一种：Path 传参。 使用 DELETE 方法，用逗号分隔将多个资源 ID 放进 URL Path 中。\nDELETE /resources/ids/1,2,3... 将多个 ID 放到 Path 传递，并且在路径中加入 ids 标识和单个 ID 接口区分开来，清晰明了，建议使用。\n第二种：Query 传参。 使用 DELETE 方法，用多个资源 ID 放进 URL Query 中。\nDELETE /resources?ids=1,2,3... 将多个 ID 放到 Query 传递，查询参数不够直观，需要在文档中明确指出如何传递多个 ID。\n注意，由于浏览器和服务器一般对 URL 的长度存在限制（没有统一标准上限，一般为 8192 字节），上面两种方式如果操作的资源过多无法实现。\n实际上批量删除操作本身是一个非常敏感的操作，一般会对批量删除资源的数量做严格限制，所以不会出现太长的 URL。\n第三种：Body 传参。 使用 DELETE 方法，将需要删除的资源的 ID 放到请求体里面。\nDELETE /resources { \u0026#34;ids\u0026#34;:[1,2,3...] } HTTP 协议标准并没有规定 DELETE 请求不能带 Body，但是 DELETE 请求体在语义上没有意义，一些网关、代理、防火墙在收到 DELETE 请求后，会把请求的 Body 直接剥离掉，所以不建议 DELETE 携带 Body。\n第四种：POST + Body 传参。 改用 POST 方法，将需要删除资源的 ID 放到请求体。\nPOST /resources Content-Type: application/json { \u0026#34;method\u0026#34;: \u0026#34;delete\u0026#34;, \u0026#34;ids\u0026#34;: [1, 2, 3] } 使用 POST 语义上与删除动作不符。\n","permalink":"https://blog.q-song.top/posts/restful_api_images/","summary":"\u003ch3 id=\"rest-api\"\u003eREST API？\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eREST API 是当今最常见的 Web 接口形式之一 ，在确保客户端和服务器之间的顺利通信方面发挥了重要作用。\n你可以把客户端看作前端，把服务器看作后端。\n客户端（前端）和服务器（后端）之间的通信通常不是直接的。因此，我们使用 API（应用编程接口），作为客户端和服务器之间的中介。\n因为 API 在这种 client–server 通信中起着至关重要的作用，所以我们在设计 API 时应该遵循最佳实践。这有助于开发人员更好地维护和使用它们。\n本篇通过 REST API 时可以遵循的一些最佳实践。这将帮助创建高效，安全，易于使用和维护的 API。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"1什么是-rest-api\"\u003e1.什么是 REST API？\u003c/h3\u003e\n\u003cp\u003eREST 是 Representational State Transfer 的缩写。它是由 Roy Fielding 博士在 2000 年他的博士论文中提出一种软件架构风格，用于指导网络应用的设计和开发，使得 Web API（网络应用编程接口）更加简单、灵活、可扩展和易于理解。\n任何遵循 REST 设计原则的 API 都被称为 RESTful API。\n简单地说，REST API 是两台计算机通过 HTTP（超文本传输协议）进行通信的媒介，与客户端和服务器的通信方式相同。\nREST API 使用 URL 唯一标识和定位 RESTful 服务中的资源，一个完整的 URL 结构如下：\n\u003cimg loading=\"lazy\" src=\"/posts/restful_api_images/0699d80f.png\"\u003e\u003c/p\u003e\n\u003ch3 id=\"2rest-api-设计建议\"\u003e2.REST API 设计建议\u003c/h3\u003e\n\u003ch4 id=\"1-用名词表示资源\"\u003e1. 用名词表示资源\u003c/h4\u003e\n\u003cp\u003e当你设计一个 REST API 时，端点应该使用名词而非动词。\n这是因为 HTTP 方法已经以动词形式执行基本的 CRUD（创建、读取、更新、删除）操作。\nGET、POST、PUT、PATCH 和 DELETE 是最常见的 HTTP 动词。还有其他非 HTTP 标准动词，如 COPY、PURGE、LINK、UNLINK 等等。\n因此，举例来说，一个端点不应该是这样的：\u003c/p\u003e","title":"Restful API设计最佳实践?"},{"content":" 锁（Lock）是并发编程中用于保护共享资源、防止数据竞争（data race）的关键同步原语。\n1.sync.Mutex (互斥锁) 特点 同一时间只允许一个 goroutine 持有锁。 不可重入（reentrant）：同一个 goroutine 再次调用 Lock() 会导致死锁。 var mu sync.Mutex var count int func increment() { mu.Lock() defer mu.Unlock() count++ } 注意 必须配对使用：每个 Lock() 必须对应一个 Unlock()。 避免在持有锁时进行阻塞操作（如 I/O、channel 发送/接收），否则会降低并发性能。 不要复制已使用的 Mutex（因为其内部状态不可复制）。 2.sync.RWMutex 读写锁 特点 支持 多个 reader 或 一个 writer。 读锁（RLock）：允许多个 goroutine 同时读。 写锁（Lock）：独占，阻塞所有读和其他写。 适用于“读多写少”的场景。 var rwmu sync.RWMutex var cache map[string]string // 读操作 func get(key string) string { rwmu.RLock() defer rwmu.RUnlock() return cache[key] } // 写操作 func set(key, value string) { rwmu.Lock() defer rwmu.Unlock() cache[key] = value } 注意 写锁优先级问题：某些实现中，持续的读请求可能“饿死”写请求（Go 的 RWMutex 在写等待时会阻止新读者进入，缓解此问题）。 不要在读锁内修改共享数据！仅用于读取。 和 Mutex 一样，不可重入、不可复制。 3.sync.Map 并发安全的map 特点 内置并发安全的 map，内部使用分段锁或原子操作优化。 适用于读远多于写、key 集合不固定（频繁增删）的场景。 不是通用替代品，仅在特定场景比 map + RWMutex 更高效。 var m sync.Map m.Store(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;) if v, ok := m.Load(\u0026#34;key\u0026#34;); ok { fmt.Println(v) } 注意 接口类型：key 和 value 都是 interface{}，有类型转换开销。 不支持遍历快照：Range 回调期间 map 可能被修改。 不适合复杂操作（如“读-改-写”原子操作），此时仍需配合锁。 4.原子操作（sync/atomic）—— 无锁 特点 对简单类型（int32/int64/pointer 等）提供原子读写、CAS（Compare-And-Swap）。 性能极高，无 goroutine 阻塞。 适用于计数器、标志位等简单状态。 var counter int64 // 原子自增 atomic.AddInt64(\u0026amp;counter, 1) // 原子加载 val := atomic.LoadInt64(\u0026amp;counter) 注意 仅适用于对齐的、简单内存操作。 不能用于保护复杂数据结构（如 slice、struct 字段组合）。 5.使用注意 锁粒度控制 尽量缩小临界区，只保护真正需要同步的代码。\n及时释放锁资源 建议使用defer，避免异常路径漏释放。\n避免锁复制, 保证必要使用指针传递，或确保 struct 不被复制。\ntype Counter struct { mu sync.Mutex n int } c1 := Counter{} c2 := c1 // 错误！Mutex 被复制，行为未定义 过度使用 RWMutex 如果写操作频繁，RWMutex 可能比 Mutex 更慢（因管理 reader 队列开销）。\n简单共享变量 → 优先考虑 atomic。 保护复杂状态（struct/slice/map） → 用 Mutex。 高频读、低频写（如配置缓存） → 用 RWMutex。 动态 key 的 map 且读为主 → 考虑 sync.Map。 ","permalink":"https://blog.q-song.top/posts/lock_differ/","summary":"\u003cblockquote\u003e\n\u003cp\u003e锁（Lock）是并发编程中用于保护共享资源、防止数据竞争（data race）的关键同步原语。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"1syncmutex-互斥锁\"\u003e1.sync.Mutex (互斥锁)\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e特点\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e同一时间只允许一个 goroutine 持有锁。\n不可重入（reentrant）：同一个 goroutine 再次调用 Lock() 会导致死锁。\n\nvar mu sync.Mutex\nvar count int\nfunc increment() {\n    mu.Lock()\n    defer mu.Unlock()\n    count++\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003e注意\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e必须配对使用：每个 Lock() 必须对应一个 Unlock()。\n避免在持有锁时进行阻塞操作（如 I/O、channel 发送/接收），否则会降低并发性能。\n不要复制已使用的 Mutex（因为其内部状态不可复制）。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"2syncrwmutex-读写锁\"\u003e2.sync.RWMutex 读写锁\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e特点\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e支持 多个 reader 或 一个 writer。\n读锁（RLock）：允许多个 goroutine 同时读。\n写锁（Lock）：独占，阻塞所有读和其他写。\n适用于“读多写少”的场景。\n\nvar rwmu sync.RWMutex\nvar cache map[string]string\n// 读操作\nfunc get(key string) string {\n    rwmu.RLock()\n    defer rwmu.RUnlock()\n    return cache[key]\n}\n// 写操作\nfunc set(key, value string) {\n    rwmu.Lock()\n    defer rwmu.Unlock()\n    cache[key] = value\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003e注意\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e写锁优先级问题：某些实现中，持续的读请求可能“饿死”写请求（Go 的 RWMutex 在写等待时会阻止新读者进入，缓解此问题）。\n不要在读锁内修改共享数据！仅用于读取。\n和 Mutex 一样，不可重入、不可复制。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"3syncmap-并发安全的map\"\u003e3.sync.Map 并发安全的map\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e特点\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e内置并发安全的 map，内部使用分段锁或原子操作优化。\n适用于读远多于写、key 集合不固定（频繁增删）的场景。\n不是通用替代品，仅在特定场景比 map + RWMutex 更高效。\n\nvar m sync.Map\n\nm.Store(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;)\nif v, ok := m.Load(\u0026#34;key\u0026#34;); ok {\n    fmt.Println(v)\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003e注意\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e接口类型：key 和 value 都是 interface{}，有类型转换开销。\n不支持遍历快照：Range 回调期间 map 可能被修改。\n不适合复杂操作（如“读-改-写”原子操作），此时仍需配合锁。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"4原子操作syncatomic-无锁\"\u003e4.原子操作（sync/atomic）—— 无锁\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e特点\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e对简单类型（int32/int64/pointer 等）提供原子读写、CAS（Compare-And-Swap）。\n性能极高，无 goroutine 阻塞。\n适用于计数器、标志位等简单状态。\n\nvar counter int64\n// 原子自增\natomic.AddInt64(\u0026amp;counter, 1)\n// 原子加载\nval := atomic.LoadInt64(\u0026amp;counter)\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003e注意\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e仅适用于对齐的、简单内存操作。\n不能用于保护复杂数据结构（如 slice、struct 字段组合）。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"5使用注意\"\u003e5.使用注意\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e锁粒度控制\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003ccode\u003e尽量缩小临界区，只保护真正需要同步的代码。\u003c/code\u003e\u003c/p\u003e","title":"Go 中的 Lock使用?"},{"content":" Kafka 的 Rebalance (重平衡) 是 Consumer Group (消费者组) 中的一个核心机制，它用于在 Consumer Group 内部重新分配 Topic 的分区（Partition）所有权。 Rebalance 确保了在集群运行过程中，Consumer Group 里的所有消费者能均匀、独占地消费所有相关的分区。\n1.什么是 Rebalance (重平衡)？ 在 Kafka 中，一个 Consumer Group 消费一个或多个 Topic。每个分区在同一时刻只能被 Consumer Group 内的一个 Consumer 实例消费。 Rebalance 就是 Consumer Group 内部达成一致，确定“谁”来消费“哪个”分区的过程。 1.1 核心目标 负载均衡：将分区均匀地分配给组内所有健康的 Consumer 实例。 高可用性：当有 Consumer 实例失败或退出时，Rebalance 机制会将它之前负责的分区重新分配给组内其他Consumer，确保消费不会中断。 1.2 Rebalance 的过程 整个过程由 Consumer Group 的 Coordinator（协调器，通常是某个 Broker） 负责协调：\n-Join Group (加入组)：新的 Consumer 加入或旧的 Consumer 重新连接时，会向 Coordinator 发送请求。 -Sync Group (同步组)：Coordinator 在收到所有 Consumer 的 Join 请求后，会选出一个 Leader Consumer。 -分配方案：Leader Consumer 负责制定分区到 Consumer 的映射关系（分配策略）。 -执行分配：Coordinator 将分配方案通知给所有 Consumer，各个 Consumer 按照方案开始消费新分配的分区。 2.什么情况下会出现 Rebalance？ 任何导致 Consumer Group 内部成员发生变化或分区信息发生变化的操作，都会触发 Rebalance。\n2.1 Consumer 成员变化 新 Consumer 加入：启动一个新的 Consumer 实例并将其加入到现有 Consumer Group 中，以增加消费能力。 Consumer 退出（正常退出）：一个 Consumer 实例正常关闭，需要将其负责的分区释放出来。 Consumer 崩溃或掉线（非正常退出）： Consumer 实例在发送心跳（Heartbeat）给 Coordinator 的间隔内（session.timeout.ms）没有响应。 Coordinator 认为该 Consumer 死亡，将其踢出 Group，触发 Rebalance。 2.2 Topic/Partition 变化 Topic 分区数发生变化：如果一个 Group 正在消费的 Topic，其分区数量被手动增加，Group 必须进行 Rebalance 来分配新的分区。 Group 订阅的 Topic 列表发生变化：如果 Consumer Group 动态订阅了新的 Topic。 2.3 配置参数变化 心跳超时：如果 Consumer 停止向 Coordinator 发送心跳，并且超出了配置的 session.timeout.ms，Coordinator 将认为 Consumer 实例死亡，触发 Rebalance。 获取分区超时：如果 Consumer 在加入 Group 时，获取分区信息超时，也可能触发 Rebalance 尝试。 注意： Rebalance 是一个“Stop-The-World”操作。在 Rebalance 过程中，Consumer 组会暂停消费，这会引入短暂的消费延迟。因此，频繁的 Rebalance 是需要尽量避免的。\n","permalink":"https://blog.q-song.top/posts/kafka_rebalance/","summary":"\u003cblockquote\u003e\n\u003cp\u003eKafka 的 Rebalance (重平衡) 是 Consumer Group (消费者组) 中的一个核心机制，它用于在 Consumer Group 内部重新分配 Topic 的分区（Partition）所有权。\nRebalance 确保了在集群运行过程中，Consumer Group 里的所有消费者能均匀、独占地消费所有相关的分区。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"1什么是-rebalance-重平衡\"\u003e1.什么是 Rebalance (重平衡)？\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e在 Kafka 中，一个 Consumer Group 消费一个或多个 Topic。每个分区在同一时刻只能被 Consumer Group 内的一个 Consumer 实例消费。\nRebalance 就是 Consumer Group 内部达成一致，确定“谁”来消费“哪个”分区的过程。\n\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"11-核心目标\"\u003e1.1 核心目标\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e负载均衡：将分区均匀地分配给组内所有健康的 Consumer 实例。\n高可用性：当有 Consumer 实例失败或退出时，Rebalance 机制会将它之前负责的分区重新分配给组内其他Consumer，确保消费不会中断。\n\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"12-rebalance-的过程\"\u003e1.2 Rebalance 的过程\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e整个过程由 Consumer Group 的 Coordinator（协调器，通常是某个 Broker） 负责协调：\u003c/strong\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e-Join Group (加入组)：新的 Consumer 加入或旧的 Consumer 重新连接时，会向 Coordinator 发送请求。\n-Sync Group (同步组)：Coordinator 在收到所有 Consumer 的 Join 请求后，会选出一个 Leader Consumer。\n-分配方案：Leader Consumer 负责制定分区到 Consumer 的映射关系（分配策略）。\n-执行分配：Coordinator 将分配方案通知给所有 Consumer，各个 Consumer 按照方案开始消费新分配的分区。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"2什么情况下会出现-rebalance\"\u003e2.什么情况下会出现 Rebalance？\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e任何导致 Consumer Group 内部成员发生变化或分区信息发生变化的操作，都会触发 Rebalance。\u003c/strong\u003e\u003c/p\u003e","title":"Kafka的rebalance?什么情况下会出现?"},{"content":" Kafka 实现主从同步（即 Leader 副本和 Follower 副本之间的数据同步）是其保证数据高可用性和持久性的核心机制。这个过程是**异步拉取（Pull）的，并由 ISR（同步副本集合）机制严格管理。\n1.异步拉取 与一些数据库的 Push 模式不同，Kafka 的副本同步采用 Pull 模型：\n主动方 (Follower)：Follower 副本是主动方。它会不断地向 Leader 副本发送请求，请求拉取新的消息数据。 拉取单位：Follower 拉取的最小单位是 **日志段（Log Segment）**中的一批消息。 这种拉取模式允许 Follower 控制自己的复制速率。如果 Follower 暂时负载过高，它可以减慢拉取速度，避免被 Leader 的高速写入压垮。 2.关键同步指标 Follower 在同步过程中，会维护和使用两个关键的偏移量（Offset）：\nLEO (Log End Offset)：表示该 Follower 已成功写入本地日志的最新消息的下一个 Offset。 HW (High Watermark)：表示所有 ISR 集合中的副本都已经复制并确认写入的最新消息的下一个 Offset。 重要性：HW 之前的消息对 Consumer 是可见且安全的，而 HW 之后的 Leader 消息对 Consumer 是不可见的，以防 Leader 宕机导致数据丢失。 3.ISR (In-Sync Replicas) 机制的保障 同步副本集合（ISR）是衡量同步状态的核心机制：\nLeader 维护 ISR：Leader 副本负责维护 ISR 列表。ISR 列表包括 Leader 自身和所有与 Leader 保持“同步”的 Follower 副本。 同步判断标准： -Follower 必须在配置的时间阈值（replica.lag.time.max.ms）内持续向 Leader 发送拉取请求。 -Follower 的 LEO 必须与 Leader 的 LEO 保持在一个可接受的范围内。 副本移出：如果 Follower 无法满足上述条件（如网络延迟过高、宕机），它会被 Leader 移出 ISR。 数据持久性保证：当生产者（Producer）设置为 acks=all 时，Leader 必须等待 ISR 中的所有副本都确认写入了消息，才会返回 ACK 成功。这确保了只要 ISR 中有一个副本存活，数据就不会丢失。 4.主从同步流程简述 Follower 发送 Fetch 请求：Follower 向 Leader 发送 Fetch Request，请求从自己的 LEO 开始的新消息。 Leader 发送消息：Leader 从自己的日志中读取从 Follower LEO 开始的消息，并返回给 Follower。 Follower 写入并更新 LEO：Follower 接收到消息后，将其追加写入到自己的本地日志中，并更新自己的 LEO。 Leader 更新 HW：Leader 收到 Follower 的成功响应后，会检查 所有 ISR 副本的 LEO，并更新 HW 为所有副本 LEO 的最小值。 ","permalink":"https://blog.q-song.top/posts/kafka_sync/","summary":"\u003cblockquote\u003e\n\u003cp\u003eKafka 实现主从同步（即 Leader 副本和 Follower 副本之间的数据同步）是其保证数据高可用性和持久性的核心机制。这个过程是**异步拉取（Pull）的，并由 ISR（同步副本集合）机制严格管理。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"1异步拉取\"\u003e1.异步拉取\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e与一些数据库的 Push 模式不同，Kafka 的副本同步采用 Pull 模型：\u003c/strong\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e主动方 (Follower)：Follower 副本是主动方。它会不断地向 Leader 副本发送请求，请求拉取新的消息数据。\n拉取单位：Follower 拉取的最小单位是 **日志段（Log Segment）**中的一批消息。\n这种拉取模式允许 Follower 控制自己的复制速率。如果 Follower 暂时负载过高，它可以减慢拉取速度，避免被 Leader 的高速写入压垮。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"2关键同步指标\"\u003e2.关键同步指标\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eFollower 在同步过程中，会维护和使用两个关键的偏移量（Offset）：\u003c/strong\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eLEO (Log End Offset)：表示该 Follower 已成功写入本地日志的最新消息的下一个 Offset。\nHW (High Watermark)：表示所有 ISR 集合中的副本都已经复制并确认写入的最新消息的下一个 Offset。\n重要性：HW 之前的消息对 Consumer 是可见且安全的，而 HW 之后的 Leader 消息对 Consumer 是不可见的，以防 Leader 宕机导致数据丢失。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"3isr-in-sync-replicas-机制的保障\"\u003e3.ISR (In-Sync Replicas) 机制的保障\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e同步副本集合（ISR）是衡量同步状态的核心机制：\u003c/strong\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eLeader 维护 ISR：Leader 副本负责维护 ISR 列表。ISR 列表包括 Leader 自身和所有与 Leader 保持“同步”的 Follower 副本。\n同步判断标准：\n -Follower 必须在配置的时间阈值（replica.lag.time.max.ms）内持续向 Leader 发送拉取请求。\n -Follower 的 LEO 必须与 Leader 的 LEO 保持在一个可接受的范围内。\n副本移出：如果 Follower 无法满足上述条件（如网络延迟过高、宕机），它会被 Leader 移出 ISR。\n数据持久性保证：当生产者（Producer）设置为 acks=all 时，Leader 必须等待 ISR 中的所有副本都确认写入了消息，才会返回 ACK 成功。这确保了只要 ISR 中有一个副本存活，数据就不会丢失。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"4主从同步流程简述\"\u003e4.主从同步流程简述\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eFollower 发送 Fetch 请求：Follower 向 Leader 发送 Fetch Request，请求从自己的 LEO 开始的新消息。\nLeader 发送消息：Leader 从自己的日志中读取从 Follower LEO 开始的消息，并返回给 Follower。\nFollower 写入并更新 LEO：Follower 接收到消息后，将其追加写入到自己的本地日志中，并更新自己的 LEO。\nLeader 更新 HW：Leader 收到 Follower 的成功响应后，会检查 所有 ISR 副本的 LEO，并更新 HW 为所有副本 LEO 的最小值。\n\u003c/code\u003e\u003c/pre\u003e","title":"Kafka如何实现主从同步?"},{"content":" 在 Go 语言中，类型断言（Type Assertion） 是一种用于从接口值中提取其底层具体类型的操作。它是 Go 实现多态和类型安全的重要机制之一。\n一、基本语法 value, ok := interfaceVar.(ConcreteType)\ninterfaceVar：一个接口类型的变量 ConcreteType：你期望它实际存储的具体类型（如 int, string, MyStruct 等） value：如果断言成功，就是该类型的值 ok：布尔值，表示断言是否成功\n二、为什么需要类型断言？ Go 的接口（interface）可以存储任何类型的值，但当你想使用这个值的具体方法或字段时，就必须知道它的真实类型。\nvar i interface{} = \u0026ldquo;hello\u0026rdquo;\n// 我知道它是 string，但接口本身不能直接调用 len() s := i.(string) // 类型断言：断言 i 是 string fmt.Println(len(s)) // 现在可以了\n三、两种写法 安全断言（推荐） —— 带 ok 判断 s, ok := i.(string) if ok { fmt.Println(\u0026#34;字符串长度:\u0026#34;, len(s)) } else { fmt.Println(\u0026#34;i 不是一个字符串\u0026#34;) } 优点：不会 panic，适合不确定类型时使用。 直接断言 —— 不检查 ok s := i.(string) // 如果 i 不是 string，会 panic！ 面临的风险：如果类型不匹配，程序会崩溃（panic）。 仅在你100%确定类型时使用。\n四、典型使用场景 场景1：从 interface{} 中取值（比如 JSON 解析）\ndata := map[string]interface{}{ \u0026#34;name\u0026#34;: \u0026#34;Alice\u0026#34;, \u0026#34;age\u0026#34;: 25, } name, _ := data[\u0026#34;name\u0026#34;].(string) age, _ := data[\u0026#34;age\u0026#34;].(int) fmt.Printf(\u0026#34;姓名: %s, 年龄: %d\\n\u0026#34;, name, age) json.Unmarshal 默认把对象解析成 map[string]interface{}，就需要类型断言。\n场景2：处理不同类型的事件\ntype Event interface{} type ClickEvent struct{ X, Y int } type KeyEvent struct{ Key string } func HandleEvent(e Event) { switch v := e.(type) { case ClickEvent: fmt.Printf(\u0026#34;点击事件: (%d, %d)\\n\u0026#34;, v.X, v.Y) case KeyEvent: fmt.Printf(\u0026#34;按键事件: %s\\n\u0026#34;, v.Key) default: fmt.Println(\u0026#34;未知事件\u0026#34;) } } 这里用了 类型选择（type switch），是类型断言的高级形式。\n五、常见错误 错误1：断言失败导致 panic\nvar i interface{} = 42 s := i.(string) // panic: interface is int, not string 优雅做法：\ns, ok := i.(string) if !ok { fmt.Println(\u0026#34;不是字符串\u0026#34;) } 错误2：对 nil 接口断言\nvar i interface{} // nil s, ok := i.(string) // ok == false 即使底层类型是 string，但值是 nil，断言也会失败。\n","permalink":"https://blog.q-song.top/posts/type_assertion/","summary":"\u003cblockquote\u003e\n\u003cp\u003e在 Go 语言中，类型断言（Type Assertion） 是一种用于从接口值中提取其底层具体类型的操作。它是 Go 实现多态和类型安全的重要机制之一。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"一基本语法\"\u003e一、基本语法\u003c/h2\u003e\n\u003cp\u003evalue, ok := interfaceVar.(ConcreteType)\u003c/p\u003e\n\u003cp\u003einterfaceVar：一个接口类型的变量\nConcreteType：你期望它实际存储的具体类型（如 int, string, MyStruct 等）\nvalue：如果断言成功，就是该类型的值\nok：布尔值，表示断言是否成功\u003c/p\u003e\n\u003ch2 id=\"二为什么需要类型断言\"\u003e二、为什么需要类型断言？\u003c/h2\u003e\n\u003cp\u003eGo 的接口（interface）可以存储任何类型的值，但当你想使用这个值的具体方法或字段时，就必须知道它的真实类型。\u003c/p\u003e\n\u003cp\u003evar i interface{} = \u0026ldquo;hello\u0026rdquo;\u003c/p\u003e\n\u003cp\u003e// 我知道它是 string，但接口本身不能直接调用 len()\ns := i.(string)  // 类型断言：断言 i 是 string\nfmt.Println(len(s))  // 现在可以了\u003c/p\u003e\n\u003ch2 id=\"三两种写法\"\u003e三、两种写法\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e安全断言（推荐） —— 带 ok 判断\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e\n   s, ok := i.(string)\n   if ok {\n   fmt.Println(\u0026#34;字符串长度:\u0026#34;, len(s))\n   } else {\n   fmt.Println(\u0026#34;i 不是一个字符串\u0026#34;)\n   }\n\u003c/code\u003e\u003c/pre\u003e\u003cpre\u003e\u003ccode\u003e优点：不会 panic，适合不确定类型时使用。\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e直接断言 —— 不检查 ok\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e   s := i.(string)  // 如果 i 不是 string，会 panic！\n\u003c/code\u003e\u003c/pre\u003e\u003cpre\u003e\u003ccode\u003e面临的风险：如果类型不匹配，程序会崩溃（panic）。\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e仅在你100%确定类型时使用。\u003c/p\u003e","title":"Type Assertion 类型断言"},{"content":" 分布式锁是分布式系统从“松散运行”走向“协作、可靠运行”的关键桥梁。\n1.什么是分布式锁? 分布式锁是用于在分布式系统中协调多个进程或线程访问共享资源的一种机制，确保在任何时刻只有一个客户端能够操作特定的资源，从而保证数据的一致性。 2.分布式锁的基本要素 无论是基于 Redis、ZooKeeper 还是数据库实现，一个可靠的分布式锁必须满足三个要素： *加锁（Lock）：在资源上设置一个锁的标记。 *设置过期时间（TTL）：防止客户端宕机导致锁无法释放，造成死锁。这是分布式锁与本地锁（如 Java 的 ReentrantLock）最核心的区别。 *释放锁（Unlock）：客户端完成操作后，安全地移除锁。 3.分布式锁面临问题和解决 3.1 死锁 如果客户端在获取锁后，由于某种原因（例如，程序崩溃）未能正常释放锁，导致锁一直被占用，其他客户端无法获取锁，造成死锁。解决方案：在加锁的同时设置过期时间，即使客户端未能正常释放锁，锁也会在过期后自动释放。或者使用 Redlock 算法，提高锁的可靠性，防止死锁。 3.2 锁的误删 -如果客户端 A 获取锁后，由于执行时间过长，导致锁过期自动释放。此时，客户端 B 获取了锁。然后，客户端 A 执行完业务逻辑后，尝试释放锁，但实际上释放的是客户端 B 的锁，造成锁的误删除。解决方案：在加锁时，将锁的值设置为一个唯一标识（例如，UUID），在释放锁时，先判断锁的值是否与自己的唯一标识相等，如果相等，则释放锁；否则，不释放锁。此过程要保证原子性，可以使用 Lua 脚本实现。 -在网络分区的情况下，可能会导致多个进程同时认为自己持有锁。解决方案：在获取锁时生成一个唯一的 UUID，并将其存储在锁的 Key 中。在释放锁时，先检查当前存储的 UUID 是否与自己的 UUID 匹配，只有匹配时才释放锁。 3.3 锁的续期 如果客户端在加锁后，执行时间超过了锁的过期时间，导致锁被自动释放。此时，其他客户端可能会获取锁，造成并发问题。解决方案：客户端在获取锁后，启动一个后台线程，定期检查锁的剩余时间，如果剩余时间小于一定阈值，则使用 EXPIRE 命令续期锁的过期时间。此流程可以自己实现，也可以使用开源框架，例如Redisson 框架不仅提供了自动续期的功能，还可以简化分布式锁的实现。 3.4 锁的竞争 在高并发场景下，多个进程可能会同时竞争锁，导致锁的获取失败率较高。解决方案：可以使用随机退避重试策略，在获取锁失败后，随机等待一段时间后再次重试。 3.5 锁的重入性 如果同一个进程多次尝试获取锁，可能会导致锁的获取失败。解决方案：在锁的 Key 中存储一个计数器，表示当前进程获取锁的次数。每次获取锁时增加计数器，释放锁时减少计数器，只有计数器为 0 时才删除锁的 Key。 3.6 锁的公平性 多个进程同时请求锁时，可能会出现“饥饿”现象，某些进程长时间无法获取锁。解决方案：可以使用 Redis 的 List 数据结构实现排队机制，确保请求锁的进程按照顺序获取锁。或者使用成熟的分布式锁实现库，如 Redisson，它提供了公平锁和可重入锁等功能。 ","permalink":"https://blog.q-song.top/posts/distributed_lock/","summary":"\u003cblockquote\u003e\n\u003cp\u003e分布式锁是分布式系统从“松散运行”走向“协作、可靠运行”的关键桥梁。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"1什么是分布式锁\"\u003e1.什么是分布式锁?\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e分布式锁是用于在分布式系统中协调多个进程或线程访问共享资源的一种机制，确保在任何时刻只有一个客户端能够操作特定的资源，从而保证数据的一致性。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"2分布式锁的基本要素\"\u003e2.分布式锁的基本要素\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e无论是基于 Redis、ZooKeeper 还是数据库实现，一个可靠的分布式锁必须满足三个要素：\n*加锁（Lock）：在资源上设置一个锁的标记。\n*设置过期时间（TTL）：防止客户端宕机导致锁无法释放，造成死锁。这是分布式锁与本地锁（如 Java 的 ReentrantLock）最核心的区别。\n*释放锁（Unlock）：客户端完成操作后，安全地移除锁。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"3分布式锁面临问题和解决\"\u003e3.分布式锁面临问题和解决\u003c/h3\u003e\n\u003ch4 id=\"31-死锁\"\u003e3.1 死锁\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e如果客户端在获取锁后，由于某种原因（例如，程序崩溃）未能正常释放锁，导致锁一直被占用，其他客户端无法获取锁，造成死锁。解决方案：在加锁的同时设置过期时间，即使客户端未能正常释放锁，锁也会在过期后自动释放。或者使用 Redlock 算法，提高锁的可靠性，防止死锁。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"32-锁的误删\"\u003e3.2 锁的误删\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e-如果客户端 A 获取锁后，由于执行时间过长，导致锁过期自动释放。此时，客户端 B 获取了锁。然后，客户端 A 执行完业务逻辑后，尝试释放锁，但实际上释放的是客户端 B 的锁，造成锁的误删除。解决方案：在加锁时，将锁的值设置为一个唯一标识（例如，UUID），在释放锁时，先判断锁的值是否与自己的唯一标识相等，如果相等，则释放锁；否则，不释放锁。此过程要保证原子性，可以使用 Lua 脚本实现。\n-在网络分区的情况下，可能会导致多个进程同时认为自己持有锁。解决方案：在获取锁时生成一个唯一的 UUID，并将其存储在锁的 Key 中。在释放锁时，先检查当前存储的 UUID 是否与自己的 UUID 匹配，只有匹配时才释放锁。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"33-锁的续期\"\u003e3.3 锁的续期\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e如果客户端在加锁后，执行时间超过了锁的过期时间，导致锁被自动释放。此时，其他客户端可能会获取锁，造成并发问题。解决方案：客户端在获取锁后，启动一个后台线程，定期检查锁的剩余时间，如果剩余时间小于一定阈值，则使用 EXPIRE 命令续期锁的过期时间。此流程可以自己实现，也可以使用开源框架，例如Redisson 框架不仅提供了自动续期的功能，还可以简化分布式锁的实现。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"34-锁的竞争\"\u003e3.4 锁的竞争\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e在高并发场景下，多个进程可能会同时竞争锁，导致锁的获取失败率较高。解决方案：可以使用随机退避重试策略，在获取锁失败后，随机等待一段时间后再次重试。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"35-锁的重入性\"\u003e3.5 锁的重入性\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e如果同一个进程多次尝试获取锁，可能会导致锁的获取失败。解决方案：在锁的 Key 中存储一个计数器，表示当前进程获取锁的次数。每次获取锁时增加计数器，释放锁时减少计数器，只有计数器为 0 时才删除锁的 Key。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"36-锁的公平性\"\u003e3.6 锁的公平性\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e多个进程同时请求锁时，可能会出现“饥饿”现象，某些进程长时间无法获取锁。解决方案：可以使用 Redis 的 List 数据结构实现排队机制，确保请求锁的进程按照顺序获取锁。或者使用成熟的分布式锁实现库，如 Redisson，它提供了公平锁和可重入锁等功能。\n\u003c/code\u003e\u003c/pre\u003e","title":"了解分布式锁吗?"},{"content":" 栈分配和堆分配确实都发生在“对象分配器”的分配阶段， 但它们走的是不同的路径： 栈分配走的是编译期静态分配； 堆分配走的是运行时对象分配器（runtime.mallocgc）。\n1.程序启动阶段 Go 运行时启动时（runtime 初始化），会： 向操作系统申请一大块虚拟内存（称为 arena）； 由 页分配器（page allocator） 管理这块内存； 构建堆内存管理结构（mheap、mcentral、mcache）。 这部分只是“预留”内存，真正的对象分配还没发生。\n2.用户程序触发分配（对象分配阶段） 当用户代码中创建变量时，比如：\nx := MyStruct{} 编译器会在编译阶段决定这个对象是： 分配在栈上（stack allocation） 还是分配在堆上（heap allocation） 这个决策是通过 逃逸分析（Escape Analysis） 完成的。\n3.栈分配的过程 如果编译器认为对象只在当前函数作用域内使用，不会被外部引用： 这个对象会直接分配在栈上； 不会调用运行时的内存分配器； 栈内存是随函数调用帧自动增长/释放的； GC 不需要扫描或回收它。 \u0026gt; 关键：栈分配是编译期确定的，性能最好。 4.堆分配的过程 如果对象被闭包引用、返回地址或传递给其他 goroutine，则会发生逃逸： 编译器在生成代码时，会调用运行时的分配器 runtime.mallocgc； mallocgc 会从当前 P 的 mcache 尝试获取一个合适的 span； 若 mcache 缓存不足，就从 mcentral → mheap 逐层申请； 分配完成后，GC 会在堆上追踪这个对象。 \u0026gt;关键：堆分配是运行时动态完成的，涉及 GC 管理。 5.回收阶段 当对象不再被引用时，GC 会标记并清除； 被清除的内存重新回收到 mcache / mcentral / mheap； 长期未使用的页可能由scavenger（拾荒器）归还给 OS。 6.对比栈和堆分配 类型 分配阶段 分配位置 分配速度 是否由 GC 管理 是否逃逸 栈分配 编译期（静态） 每个 goroutine 的调用栈 极快 否 否 堆分配 运行时（动态） 运行时堆（mheap） 慢 是 是 ","permalink":"https://blog.q-song.top/posts/memory_management/","summary":"\u003cblockquote\u003e\n\u003cp\u003e栈分配和堆分配确实都发生在“对象分配器”的分配阶段，\n但它们走的是不同的路径：\n栈分配走的是编译期静态分配；\n堆分配走的是运行时对象分配器（runtime.mallocgc）。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"1程序启动阶段\"\u003e1.程序启动阶段\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e Go 运行时启动时（runtime 初始化），会：\n向操作系统申请一大块虚拟内存（称为 arena）；\n由 页分配器（page allocator） 管理这块内存；\n构建堆内存管理结构（mheap、mcentral、mcache）。\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003e这部分只是“预留”内存，真正的对象分配还没发生。\u003c/strong\u003e\u003c/p\u003e\n\u003ch3 id=\"2用户程序触发分配对象分配阶段\"\u003e2.用户程序触发分配（对象分配阶段）\u003c/h3\u003e\n\u003cp\u003e当用户代码中创建变量时，比如：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ex := MyStruct{}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e编译器会在编译阶段决定这个对象是：\n分配在栈上（stack allocation）\n还是分配在堆上（heap allocation）\n这个决策是通过 逃逸分析（Escape Analysis） 完成的。\u003c/p\u003e\n\u003ch3 id=\"3栈分配的过程\"\u003e3.栈分配的过程\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e如果编译器认为对象只在当前函数作用域内使用，不会被外部引用：\n这个对象会直接分配在栈上；\n不会调用运行时的内存分配器；\n栈内存是随函数调用帧自动增长/释放的；\nGC 不需要扫描或回收它。\n\u0026gt; 关键：栈分配是编译期确定的，性能最好。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"4堆分配的过程\"\u003e4.堆分配的过程\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e如果对象被闭包引用、返回地址或传递给其他 goroutine，则会发生逃逸：\n编译器在生成代码时，会调用运行时的分配器 runtime.mallocgc；\nmallocgc 会从当前 P 的 mcache 尝试获取一个合适的 span；\n若 mcache 缓存不足，就从 mcentral → mheap 逐层申请；\n分配完成后，GC 会在堆上追踪这个对象。\n\u0026gt;关键：堆分配是运行时动态完成的，涉及 GC 管理。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"5回收阶段\"\u003e5.回收阶段\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e当对象不再被引用时，GC 会标记并清除；\n被清除的内存重新回收到 mcache / mcentral / mheap；\n长期未使用的页可能由scavenger（拾荒器）归还给 OS。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"6对比栈和堆分配\"\u003e6.对比栈和堆分配\u003c/h3\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003e类型\u003c/th\u003e\n          \u003cth\u003e分配阶段\u003c/th\u003e\n          \u003cth\u003e分配位置\u003c/th\u003e\n          \u003cth\u003e分配速度\u003c/th\u003e\n          \u003cth\u003e是否由 GC 管理\u003c/th\u003e\n          \u003cth\u003e是否逃逸\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e栈分配\u003c/td\u003e\n          \u003ctd\u003e编译期（静态）\u003c/td\u003e\n          \u003ctd\u003e每个 goroutine 的调用栈\u003c/td\u003e\n          \u003ctd\u003e极快\u003c/td\u003e\n          \u003ctd\u003e否\u003c/td\u003e\n          \u003ctd\u003e否\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e堆分配\u003c/td\u003e\n          \u003ctd\u003e运行时（动态）\u003c/td\u003e\n          \u003ctd\u003e运行时堆（mheap）\u003c/td\u003e\n          \u003ctd\u003e慢\u003c/td\u003e\n          \u003ctd\u003e是\u003c/td\u003e\n          \u003ctd\u003e是\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e","title":"你了解内存管理吗?"},{"content":"1.为什么会不一致 ？ Redis 是缓存层，数据库是持久层。 二者数据可能不一致的原因包括： 更新数据库成功，但更新缓存失败； 缓存提前过期； 并发写操作覆盖（顺序问题）； 异步更新延迟。 2.更新策略 2.1 Cache Aside（旁路缓存） 读操作 1. 读缓存 2. 如果缓存不存在 ,再读数据库 3. 将数据写入缓存（设置过期时间） 写操作: 先更新数据库,再删除缓存 缺点:删除缓存可能失败；删除顺序不当会不一致 2.2 Read/Write Through（读写穿透） 应用不直接访问DB，所有读写都经由缓存代理完成 缺点:实现复杂，性能略低\t2.3 Write Behind（异步写回） 只写缓存，由缓存异步刷回数据库\t缺点:容易丢数据\t3.处理并发问题 3.1延迟双删策略（Double Delete） 1. 更新数据库； 2. 删除缓存； 3. 延迟 500ms 再删一次缓存。 //可以应对并发中缓存被“脏写”回的情况。 3.2异步消息队列（MQ） 数据更新时发送 MQ 消息，异步同步缓存状态。\n3.3分布式锁 保证更新操作串行执行，避免交叉覆盖。\n","permalink":"https://blog.q-song.top/posts/redis_db_consitent/","summary":"\u003ch3 id=\"1为什么会不一致-\"\u003e1.为什么会不一致 ？\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eRedis 是缓存层，数据库是持久层。\n二者数据可能不一致的原因包括：\n更新数据库成功，但更新缓存失败；\n缓存提前过期；\n并发写操作覆盖（顺序问题）；\n异步更新延迟。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"2更新策略\"\u003e2.更新策略\u003c/h3\u003e\n\u003ch4 id=\"21-cache-aside旁路缓存\"\u003e2.1 Cache Aside（旁路缓存）\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e读操作\n1. 读缓存\n2. 如果缓存不存在 ,再读数据库\n3. 将数据写入缓存（设置过期时间）\n写操作: 先更新数据库,再删除缓存\n\n缺点:删除缓存可能失败；删除顺序不当会不一致\n\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"22-readwrite-through读写穿透\"\u003e2.2 Read/Write Through（读写穿透）\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e应用不直接访问DB，所有读写都经由缓存代理完成\n\n缺点:实现复杂，性能略低\t\n\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"23-write-behind异步写回\"\u003e2.3 Write Behind（异步写回）\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e只写缓存，由缓存异步刷回数据库\t\n\n缺点:容易丢数据\t\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"3处理并发问题\"\u003e3.处理并发问题\u003c/h3\u003e\n\u003ch4 id=\"31延迟双删策略double-delete\"\u003e3.1延迟双删策略（Double Delete）\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e1. 更新数据库；\n2. 删除缓存；\n3. 延迟 500ms 再删一次缓存。\n//可以应对并发中缓存被“脏写”回的情况。\n\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"32异步消息队列mq\"\u003e3.2异步消息队列（MQ）\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e数据更新时发送 MQ 消息，异步同步缓存状态。\u003c/strong\u003e\u003c/p\u003e\n\u003ch4 id=\"33分布式锁\"\u003e3.3分布式锁\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e保证更新操作串行执行，避免交叉覆盖。\u003c/strong\u003e\u003c/p\u003e","title":"如何保证 Redis 与数据库的数据一致性?"},{"content":"1.什么是“重锁”（Heavy Lock） 在 Go 性能调优或并发编程中，我们常说的 “重锁”（heavy lock）不是官方术语，而是一个工程上的概念，指的是：锁竞争严重、临界区较大、持锁时间较长的互斥锁（sync.Mutex）。\n1.多个 goroutine 同时频繁地去争夺同一把锁；\n2.加锁的代码块中做了比较“重”的操作（比如 I/O、JSON 编码、数据库操作）；\n导致 goroutine 阻塞、上下文切换频繁，最终造成性能瓶颈。\n2.为什么会出现“重锁”问题 1.临界区太大（锁保护的范围过广）；\n2.频繁写操作导致锁争用；\n3.使用全局变量或共享状态；\n4.没有分片（sharding）或局部化锁机制；\n5.锁中包含耗时操作（例如网络请求、磁盘 I/O）。\nvar mu sync.Mutex var cache = make(map[string]string) func Set(k, v string) { mu.Lock() defer mu.Unlock() cache[k] = v } #当高并发调用 Set() 时，所有 goroutine 都在争抢同一把 mu，这就形成“重锁”。 3.优化思路与替代方案 3.1 使用 sync.Map 适用于读多写少的场景：\nvar m sync.Map m.Store(\u0026quot;a\u0026quot;, 1) v, _ := m.Load(\u0026quot;a\u0026quot;) #sync.Map 内部采用分片和原子操作，避免了全局锁竞争。 3.2 使用原子操作（sync/atomic） 适用于简单的计数、标志位等操作：\nvar count int64 atomic.AddInt64(\u0026amp;count, 1) #无锁化操作，性能更高，且不阻塞其他 goroutine。 3.3 优化锁粒度（细化锁） 将一把全局锁拆分成多把局部锁：\nvar locks [16]sync.Mutex func getLock(key string) *sync.Mutex { return \u0026amp;locks[hash(key)%16] } #减少锁争用，提高并发性能。 ","permalink":"https://blog.q-song.top/posts/lock/","summary":"\u003ch3 id=\"1什么是重锁heavy-lock\"\u003e1.什么是“重锁”（Heavy Lock）\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e在 Go 性能调优或并发编程中，我们常说的 “重锁”（heavy lock）不是官方术语，而是一个工程上的概念，指的是：锁竞争严重、临界区较大、持锁时间较长的互斥锁（sync.Mutex）。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e1.多个 goroutine 同时频繁地去争夺同一把锁；\u003c/p\u003e\n\u003cp\u003e2.加锁的代码块中做了比较“重”的操作（比如 I/O、JSON 编码、数据库操作）；\u003c/p\u003e\n\u003cp\u003e导致 goroutine 阻塞、上下文切换频繁，最终造成性能瓶颈。\u003c/p\u003e\n\u003ch3 id=\"2为什么会出现重锁问题\"\u003e2.为什么会出现“重锁”问题\u003c/h3\u003e\n\u003cp\u003e1.临界区太大（锁保护的范围过广）；\u003c/p\u003e\n\u003cp\u003e2.频繁写操作导致锁争用；\u003c/p\u003e\n\u003cp\u003e3.使用全局变量或共享状态；\u003c/p\u003e\n\u003cp\u003e4.没有分片（sharding）或局部化锁机制；\u003c/p\u003e\n\u003cp\u003e5.锁中包含耗时操作（例如网络请求、磁盘 I/O）。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e    var mu sync.Mutex\n    var cache = make(map[string]string)\n    \n    func Set(k, v string) {\n    mu.Lock()\n    defer mu.Unlock()\n    cache[k] = v\n    }\n    #当高并发调用 Set() 时，所有 goroutine 都在争抢同一把 mu，这就形成“重锁”。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"3优化思路与替代方案\"\u003e3.优化思路与替代方案\u003c/h3\u003e\n\u003ch4 id=\"31-使用-syncmap\"\u003e3.1 使用 sync.Map\u003c/h4\u003e\n\u003cp\u003e适用于读多写少的场景：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003evar m sync.Map\nm.Store(\u0026quot;a\u0026quot;, 1)\nv, _ := m.Load(\u0026quot;a\u0026quot;)\n#sync.Map 内部采用分片和原子操作，避免了全局锁竞争。\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4 id=\"32-使用原子操作syncatomic\"\u003e3.2 使用原子操作（sync/atomic）\u003c/h4\u003e\n\u003cp\u003e适用于简单的计数、标志位等操作：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003evar count int64\natomic.AddInt64(\u0026amp;count, 1)\n#无锁化操作，性能更高，且不阻塞其他 goroutine。\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4 id=\"33-优化锁粒度细化锁\"\u003e3.3 优化锁粒度（细化锁）\u003c/h4\u003e\n\u003cp\u003e将一把全局锁拆分成多把局部锁：\u003c/p\u003e","title":"什么是“重锁” Heavy Lock?"},{"content":" 零拷贝（Zero-Copy）是一种计算机操作技术，主要应用于高性能网络和文件 I/O 领域。它的核心目标是减少 CPU 在传输数据时进行不必要的内存数据拷贝，以及减少用户空间和内核空间之间的上下文切换次数。\n1.核心原理 ？ 在传统的 I/O 操作中，数据通常需要经历四次拷贝才能完成传输（例如将文件通过网络发送给客户端）： 第一次拷贝： 数据从磁盘读取到操作系统内核的缓冲区（通常是 Page Cache）。 第二次拷贝： 数据从内核缓冲区拷贝到应用程序的用户缓冲区。 第三次拷贝： 数据从用户缓冲区拷贝回内核的 Socket 缓冲区。 第四次拷贝： 数据从 Socket 缓冲区拷贝到网络接口卡（NIC）的缓冲区，最终发送。 零拷贝技术通过特定的系统调用和硬件支持，消除了步骤 2 和 3 的 CPU 拷贝。\n2.常见的零拷贝实现方式 2.1 sendfile 这是最常见的零拷贝实现，例如 Apache Kafka 和 Nginx 等 Web 服务器广泛使用它来高效传输文件数据。 实现机制： 它将数据从一个文件描述符直接传输到另一个文件描述符（例如从磁盘文件 FD 到网络 Socket FD）。 消除拷贝： sendfile 允许数据在内核缓冲区和 Socket 缓冲区之间直接传输，跳过了用户缓冲区，从而消除了两次 CPU 拷贝。 2.2 内存映射文件 (mmap) 内存映射文件技术通过 mmap 系统调用将文件内容直接映射到进程的虚拟地址空间。 实现： 应用程序通过指针直接读写映射的内存地址，而这个地址对应的物理内存正是内核缓冲区。 消除拷贝： 它消除了数据从内核缓冲区拷贝到用户缓冲区的步骤，因为内核缓冲区和用户空间共享了同一块物理内存。 3.零拷贝的优势 降低 CPU 开销： 减少了 CPU 进行数据拷贝的工作量。 减少延迟： 数据传输路径更短。 提高吞吐量： 特别适用于高并发、I/O 密集型的场景，如文件服务器、Web 服务器和消息中间件（如 Kafka）。 ","permalink":"https://blog.q-song.top/posts/zero_copes/","summary":"\u003cblockquote\u003e\n\u003cp\u003e零拷贝（Zero-Copy）是一种计算机操作技术，主要应用于高性能网络和文件 I/O 领域。它的核心目标是减少 CPU 在传输数据时进行不必要的内存数据拷贝，以及减少用户空间和内核空间之间的上下文切换次数。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"1核心原理-\"\u003e1.核心原理 ？\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e在传统的 I/O 操作中，数据通常需要经历四次拷贝才能完成传输（例如将文件通过网络发送给客户端）：\n第一次拷贝： 数据从磁盘读取到操作系统内核的缓冲区（通常是 Page Cache）。\n第二次拷贝： 数据从内核缓冲区拷贝到应用程序的用户缓冲区。\n第三次拷贝： 数据从用户缓冲区拷贝回内核的 Socket 缓冲区。\n第四次拷贝： 数据从 Socket 缓冲区拷贝到网络接口卡（NIC）的缓冲区，最终发送。\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cstrong\u003e零拷贝技术通过特定的系统调用和硬件支持，消除了步骤 2 和 3 的 CPU 拷贝。\u003c/strong\u003e\u003c/p\u003e\n\u003ch3 id=\"2常见的零拷贝实现方式\"\u003e2.常见的零拷贝实现方式\u003c/h3\u003e\n\u003ch4 id=\"21-sendfile\"\u003e2.1 sendfile\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e这是最常见的零拷贝实现，例如 Apache Kafka 和 Nginx 等 Web 服务器广泛使用它来高效传输文件数据。\n实现机制： 它将数据从一个文件描述符直接传输到另一个文件描述符（例如从磁盘文件 FD 到网络 Socket FD）。\n消除拷贝： sendfile 允许数据在内核缓冲区和 Socket 缓冲区之间直接传输，跳过了用户缓冲区，从而消除了两次 CPU 拷贝。\n\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"22-内存映射文件-mmap\"\u003e2.2 内存映射文件 (mmap)\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e内存映射文件技术通过 mmap 系统调用将文件内容直接映射到进程的虚拟地址空间。\n实现： 应用程序通过指针直接读写映射的内存地址，而这个地址对应的物理内存正是内核缓冲区。\n消除拷贝： 它消除了数据从内核缓冲区拷贝到用户缓冲区的步骤，因为内核缓冲区和用户空间共享了同一块物理内存。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"3零拷贝的优势\"\u003e3.零拷贝的优势\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e降低 CPU 开销： 减少了 CPU 进行数据拷贝的工作量。\n减少延迟： 数据传输路径更短。\n提高吞吐量： 特别适用于高并发、I/O 密集型的场景，如文件服务器、Web 服务器和消息中间件（如 Kafka）。\n\u003c/code\u003e\u003c/pre\u003e","title":"什么是零拷贝?"},{"content":" 简介 你好！我是 Mumu，一名热爱技术与写作的创作者。\n这里记录我的学习笔记、项目、随笔与资源分享。\n我热衷于探索高效开发、开源工具和知识体系构建。\n速览 职业：软件工程师 / 后端 所在地：中国🇨🇳 擅长：Go/Docker/Kubernetes/Redis/RabbitMQ/Kafka\u0026hellip; 邮箱：tomsfamily01@gmail.com 详细介绍 我喜欢把复杂的问题拆解成可执行的小步骤——这同样适用于代码和生活。\n我的博客主要分享：实践记录、问题复现与解决方案、工具推荐与配置教程。\n如果你是初学者，欢迎从我的标签页（如 #入门）开始；\n如果你是同行，也欢迎与我交流合作。\n项目与成果 项目 介绍 — 电商：电商购物平台 \u0026amp; 管理后台 项目 地址 — 项目链接 联系我 📧 邮箱：tomsfamily01@gmail.com 🐙 GitHub：mugong-song 座右铭 悟已往之不谏，知来者之可追。\n—— 陶渊明《归去来兮辞》\n","permalink":"https://blog.q-song.top/about/","summary":"关于我的简单介绍、联系方式和创作理念。","title":"About — 关于我"},{"content":"1.垃圾回收的认识 1.1垃圾回收是什么，有什么作用 GC，全称 Garbage Collection，即垃圾回收，是一种自动内存管理的机制。 当程序向操作系统申请的内存不再需要时，垃圾回收主动将其回收并供其他代码进行内存申请 时候复用，或者将其归还给操作系统，这种针对内存级别资源的自动回收过程，即为垃圾回收。而 负责垃圾回收的程序组件，即为垃圾回收器。 垃圾回收其实是一个完美的“Simplicity is Complicated”的例子。一方面，程序员受益于 GC，也不再需要对内存进行手动的申请和释放操作，GC 在程序运行时自动释放残留的内存。另一 方面，GC 对程序员几乎不可见，仅在程序需要进行特殊优化时，通过提供可调控的 API，对 GC 的运行时机、运行开销进行把控的时候才得以现身。 通常，垃圾回收器的执行过程被划分为两个半独立的组件：\n1）赋值器（Mutator）：这一名称本质上是在指代用户态的代码。因为对垃圾回收器而言，用户 态的代码仅仅只修改对象之间的引用关系，也就是在对象图（对象之间引用关系的一个有向图）上 进行操作。 2）回收器（Collector）：负责执行垃圾回收的代码。\n1.2常见的垃圾回收的实现方式有哪些，Go使用的是什么 所有的 GC 算法其存在形式可以归结为追踪（Tracing）和引用计数（Reference Counting）这 两种形式的混合运用。\n（1）追踪式 GC 从根对象出发，根据对象之间的引用信息，一步步推进直到扫描完毕整个堆并确定需要保留的 对象，从而回收所有可回收的对象。Go、 Java、V8 对 JavaScript 的实现等均为追踪式 GC。 （2）引用计数式 GC 每个对象自身包含一个被引用的计数器，当计数器归零时自动得到回收。因为此方法缺陷较 多，在追求高性能时通常不被应用。Python、Objective-C 等均为引用计数式 GC。 比较常见的 GC 实现方式包括：\n1）追踪式，分为多种不同类型，例如： 标记清扫：从根对象出发，将确定存活的对象进行标记，并清扫可以回收的对象。 标记整理：为了解决内存碎片问题而提出，在标记过程中，将对象尽可能整理到一块连续的内 存上。 2)增量式：将标记与清扫的过程分批执行，每次执行很小的部分，从而增量推进垃圾回收，达到 近似实时、几乎无停顿的效果。 3)增量整理：在增量式的基础上，增加对对象的整理过程。 4)分代式：将对象根据存活时间的长短进行分类，存活时间小于某个值的为年轻代，存活时间大于 某个值的为老年代，永远不会参与回收的对象为永久代。并根据分代假设（如果一个对象存活时间不 长则倾向于被回收，如果一个对象已经存活很长时间则倾向于存活更长时间）对对象进行回收。 ","permalink":"https://blog.q-song.top/posts/garbage-collection/","summary":"\u003ch3 id=\"1垃圾回收的认识\"\u003e1.垃圾回收的认识\u003c/h3\u003e\n\u003ch3 id=\"11垃圾回收是什么有什么作用\"\u003e1.1垃圾回收是什么，有什么作用\u003c/h3\u003e\n\u003cp\u003eGC，全称 Garbage Collection，即垃圾回收，是一种自动内存管理的机制。\n当程序向操作系统申请的内存不再需要时，垃圾回收主动将其回收并供其他代码进行内存申请\n时候复用，或者将其归还给操作系统，这种针对内存级别资源的自动回收过程，即为垃圾回收。而\n负责垃圾回收的程序组件，即为垃圾回收器。\n垃圾回收其实是一个完美的“Simplicity is Complicated”的例子。一方面，程序员受益于\nGC，也不再需要对内存进行手动的申请和释放操作，GC 在程序运行时自动释放残留的内存。另一\n方面，GC 对程序员几乎不可见，仅在程序需要进行特殊优化时，通过提供可调控的 API，对 GC\n的运行时机、运行开销进行把控的时候才得以现身。\n通常，垃圾回收器的执行过程被划分为两个半独立的组件：\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e1）赋值器（Mutator）：这一名称本质上是在指代用户态的代码。因为对垃圾回收器而言，用户\n态的代码仅仅只修改对象之间的引用关系，也就是在对象图（对象之间引用关系的一个有向图）上\n进行操作。\n2）回收器（Collector）：负责执行垃圾回收的代码。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"12常见的垃圾回收的实现方式有哪些go使用的是什么\"\u003e1.2常见的垃圾回收的实现方式有哪些，Go使用的是什么\u003c/h3\u003e\n\u003cp\u003e所有的 GC 算法其存在形式可以归结为追踪（Tracing）和引用计数（Reference Counting）这\n两种形式的混合运用。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e（1）追踪式 GC\n从根对象出发，根据对象之间的引用信息，一步步推进直到扫描完毕整个堆并确定需要保留的\n对象，从而回收所有可回收的对象。Go、 Java、V8 对 JavaScript 的实现等均为追踪式 GC。\n（2）引用计数式 GC\n每个对象自身包含一个被引用的计数器，当计数器归零时自动得到回收。因为此方法缺陷较\n多，在追求高性能时通常不被应用。Python、Objective-C 等均为引用计数式 GC。\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e比较常见的 GC 实现方式包括：\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e1）追踪式，分为多种不同类型，例如：\n标记清扫：从根对象出发，将确定存活的对象进行标记，并清扫可以回收的对象。\n标记整理：为了解决内存碎片问题而提出，在标记过程中，将对象尽可能整理到一块连续的内\n存上。\n2)增量式：将标记与清扫的过程分批执行，每次执行很小的部分，从而增量推进垃圾回收，达到\n近似实时、几乎无停顿的效果。\n3)增量整理：在增量式的基础上，增加对对象的整理过程。\n4)分代式：将对象根据存活时间的长短进行分类，存活时间小于某个值的为年轻代，存活时间大于\n某个值的为老年代，永远不会参与回收的对象为永久代。并根据分代假设（如果一个对象存活时间不\n长则倾向于被回收，如果一个对象已经存活很长时间则倾向于存活更长时间）对对象进行回收。\n\u003c/code\u003e\u003c/pre\u003e","title":"垃圾回收机制 Garbage Collection"},{"content":" chan 是 Go 语言并发编程中最核心的概念之一，它是 Channel（通道） 类型的关键字缩写。\nChannel 的设计理念源于通信顺序进程（CSP, Communicating Sequential Processes），它提供了一种安全、同步的方式，让不同的 Goroutine（并发执行的“工人”）之间可以进行通信和数据交换。\n1.什么是 chan (通道)？ Channel 可以被理解为一个管道或队列，它具有以下核心特性：\n类型安全： Channel 只能传输它在创建时指定的特定类型的数据。 例如：chan int 只能传输 int 整数。 同步机制： Channel 默认会阻塞发送和接收操作，直到另一端准备好。 并发安全： Go 运行时保证了对 Channel 的发送和接收操作是线程安全的，无需额外的锁（sync.Mutex）。 2.chan 怎么使用？ 使用 Channel 主要分为三个步骤：创建、发送、接收。\n2.1 创建 Channel 使用 make 函数创建 Channel。\n//无缓冲通道 (Unbuffered) ch := make(chan Type) //容量为 0。发送和接收操作必须同时准备好，否则先执行的操作会一直阻塞，直到另一个操作发生。用于严格的同步。 ch := make(chan Type, N) //有缓冲通道 (Buffered) //容量为 N。通道可以存储 N个元素。只有当通道满了（发送）或空了（接收）时，操作才会阻塞。用于解耦和提高吞吐量。 dataCh := make(chan string) // 无缓冲，用于同步信号 taskCh := make(chan int, 10) // 有缓冲，容量为 10，用于传输任务 类型 语法 目的 切片 make([]Type, length, capacity) 分配底层数组，设置切片的长度和容量。 映射 make(map[KeyType]ValueType, capacity) 分配和初始化哈希表结构。 通道 make(chan Type, capacity) 创建通道并设置其缓冲大小。 2.2 发送数据 使用箭头操作符 \u0026lt;- 将数据发送到 Channel。\nch \u0026lt;- value //示例： taskCh \u0026lt;- 5 // 将整数 5 发送到 taskCh~~~ 2.3 接收数据 使用箭头操作符 \u0026lt;- 从 Channel 接收数据。\nvalue := \u0026lt;-ch // 接收数据，并赋值给 value value, ok := \u0026lt;-ch // 接收数据，并检查通道是否已关闭 示例 // 接收并赋值 taskId := \u0026lt;-taskCh // 接收并检查状态（常用于循环接收） id, open := \u0026lt;-taskCh if !open { // 通道已被关闭且数据已取完 } 3.使用的时候要注意什么？ 使用 Channel 必须非常小心，错误的用法可能导致程序死锁、数据丢失或性能问题。\n3.1避免死锁 (Deadlock) 死锁是使用 Channel 时最常见的问题。 如果一个 Goroutine 试图发送数据到一个无缓冲通道，但没有另一个 Goroutine 准备好接收，该 Goroutine 就会永远阻塞，Go 运行时会检测到这种情况并报告致命错误：fatal error: all goroutines are asleep - deadlock!\n规则： 无缓冲通道 总是需要一个发送方和一个接收方同时在场。 避免： 绝对不要在同一个 Goroutine 中对无缓冲通道进行发送和接收操作。 3.2关闭 Channel Channel 可以通过 close(ch) 函数关闭，表示不会再有数据发送。\n只能发送方关闭： 应该由发送方来关闭 Channel，而不是接收方。 重复关闭 panic： 重复关闭一个 Channel 会导致 panic。 关闭后的接收： 关闭后，接收方仍可以接收到通道中剩余的数据。当数据取完后，接收操作会立即返回该类型的零值，ok 状态为 false。 3.3缓冲区的误解 有缓冲通道 不是无限队列。一旦缓冲区满了，发送操作仍然会阻塞。 合理设置缓冲区大小是提高性能的关键，但过大或过小都可能带来问题。 3.4使用 select 语句处理多 Channel 和超时 当 Goroutine 需要同时监听多个 Channel 的读写操作时，必须使用 select 语句。\nselect 语句可以实现： 监听多个输入 Channel。 监听多个输出 Channel。 通过 default 块实现非阻塞操作。 结合 time.After 实现超时（Timeout）机制。 具体实现\nselect { case msg := \u0026lt;-ch1: // 接收到 ch1 的数据 case ch2 \u0026lt;- \u0026#34;hi\u0026#34;: // 成功发送数据到 ch2 case \u0026lt;-time.After(5 * time.Second): // 超时处理 default: // 如果没有任何 Channel 准备好，立即执行 default (非阻塞) } ","permalink":"https://blog.q-song.top/posts/chan_usage/","summary":"\u003cblockquote\u003e\n\u003cp\u003echan 是 Go 语言并发编程中最核心的概念之一，它是 Channel（通道） 类型的关键字缩写。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003cblockquote\u003e\n\u003cp\u003eChannel 的设计理念源于通信顺序进程（CSP, Communicating Sequential Processes），它提供了一种安全、同步的方式，让不同的 Goroutine（并发执行的“工人”）之间可以进行通信和数据交换。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"1什么是-chan-通道\"\u003e1.什么是 chan (通道)？\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eChannel 可以被理解为一个管道或队列，它具有以下核心特性：\u003c/strong\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e类型安全： Channel 只能传输它在创建时指定的特定类型的数据。\n例如：chan int 只能传输 int 整数。\n同步机制： Channel 默认会阻塞发送和接收操作，直到另一端准备好。\n并发安全： Go 运行时保证了对 Channel 的发送和接收操作是线程安全的，无需额外的锁（sync.Mutex）。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"2chan-怎么使用\"\u003e2.chan 怎么使用？\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e使用 Channel 主要分为三个步骤：创建、发送、接收。\u003c/strong\u003e\u003c/p\u003e\n\u003ch4 id=\"21-创建-channel\"\u003e2.1 创建 Channel\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e使用 make 函数创建 Channel。\u003c/strong\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e//无缓冲通道 (Unbuffered)\nch := make(chan Type)\n//容量为 0。发送和接收操作必须同时准备好，否则先执行的操作会一直阻塞，直到另一个操作发生。用于严格的同步。\n\nch := make(chan Type, N)\n//有缓冲通道 (Buffered)\n//容量为 N。通道可以存储 N个元素。只有当通道满了（发送）或空了（接收）时，操作才会阻塞。用于解耦和提高吞吐量。\n\ndataCh := make(chan string)       // 无缓冲，用于同步信号\ntaskCh := make(chan int, 10)      // 有缓冲，容量为 10，用于传输任务\n\u003c/code\u003e\u003c/pre\u003e\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: left\"\u003e类型\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e语法\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e目的\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003cstrong\u003e切片\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003emake([]Type, length, capacity)\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e分配底层数组，设置切片的长度和容量。\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003cstrong\u003e映射\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003emake(map[KeyType]ValueType, capacity)\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e分配和初始化哈希表结构。\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003cstrong\u003e通道\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003emake(chan Type, capacity)\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e创建通道并设置其缓冲大小。\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch4 id=\"22-发送数据\"\u003e2.2 发送数据\u003c/h4\u003e\n\u003cp\u003e\u003cstrong\u003e使用箭头操作符 \u0026lt;- 将数据发送到 Channel。\u003c/strong\u003e\u003c/p\u003e","title":"你会使用chan吗?"},{"content":"Go sheduler是什么? Go 程序的执行有两个层面：Go Program 和 Runtime，即用户程序和运行时。它们之间通过函数调用来实现内存管理、channel 通信、goroutine 创建等功能。用户程序进行的系统调用都会被 Runtime 拦截，以此来帮助它进行调度以及垃圾回收相关的工作。\nGo scheduler 可以说是 Go 运行时的一个最重要的 部分了。 Runtime 维护所有的 goroutine ，并通过 scheduler 来进行调度。goroutine 和 threads 是独立的， 但是 goroutine 要依赖 threads 才能执行。 Go 程序执行的高效和 scheduler 的调度是分不开的。 实际上在操作系统看来，所有的程序都是在执行多线程。将 goroutine 调度到线程上执行，仅仅是 runtime 层面的一个概念，在操作系统之上的层面，操作系统并不能感知到 goroutine 的存在。\nG、M、P三个基础的结构体来实现 goroutine 的调度： G 代表一个 goroutine，它包含：表示 goroutine 栈的一些字段，指示当前 goroutine 的状态，指示当前运行到的指令地址，也就是 PC 值。 M 表示内核线程，包含正在运行的 goroutine 等字段。 P 代表一个虚拟的CPU Processor，它维护一个处于 Runnable 状态的 goroutine 队列，M 需要获得 P 才能运行 G。 当然还有一个核心的结构体：sched，它总揽全局，维持整个调度器的运行。 Runtime 起始时会启动一些 G：垃圾回收的 G，执行调度的 G，运行用户代码的 G；并且会创建一 个 M 用来开始 G 的运行。随着时间的推移，G和M的创建数量逐渐增多。 在 Go 的早期版本，并没有 P 这个结构体，M 必须从一个全局的队列里获取要运行的 G，因此需要获取一个全局的锁，当并发量大的时候，锁就成了瓶颈。后来调度器在 Dmitry Vyukov (Go 语言运行时 runtime 和调度器的核心贡献者之一) ，加 上了 P 结构体。每个 P 维护一个处于 Runnable 状态的 G 的队列，解决了原来的全局锁问题。\nGo scheduler 的目标：将 goroutine 调度到内核线程上。 Go scheduler 的核心思想是： 1）重用线程。 2）限制同时运行（不包含阻塞）的线程数为 N，N 等于 CPU 的核心数目。 3）线程私有 runqueues，并且可以从其他线程偷取 goroutine 来运行，线程阻塞后，可以将 runqueues 传递给其他线程。 为什么需要 P 这个组件，直接把 runqueues 放到 M 不行吗？ 需要 P 组件的原因是当一个线程阻塞的时候，将和它绑定的 P 上的 goroutine 转移到其他线程。 例如当线程进行阻塞系统调用的时候，这时它无法再执行其他代码，因此可以将与其相关联的 P 上的 goroutine 分配给其他线程运行。 另外，Go scheduler 会启动一个后台线程 sysmon，用来检测长时间（超过 10 ms）运行的 goroutine，将其“停 靠”到 global runqueues。这是一个全局的 runqueue，优先级比较低，以示惩罚。 通常讲到 Go scheduler 都会提到 GPM 模型，来一 个个地看。\n","permalink":"https://blog.q-song.top/posts/gmp/","summary":"\u003ch3 id=\"go-sheduler是什么\"\u003eGo sheduler是什么?\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eGo 程序的执行有两个层面：Go Program 和 Runtime，即用户程序和运行时。它们之间通过函数调用来实现内存管理、channel 通信、goroutine 创建等功能。用户程序进行的系统调用都会被\nRuntime 拦截，以此来帮助它进行调度以及垃圾回收相关的工作。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eGo scheduler 可以说是 Go 运行时的一个最重要的 部分了。 Runtime 维护所有的 goroutine ，并通过\nscheduler 来进行调度。goroutine 和 threads 是独立的， 但是 goroutine 要依赖 threads 才能执行。\nGo 程序执行的高效和 scheduler 的调度是分不开的。\n实际上在操作系统看来，所有的程序都是在执行多线程。将 goroutine 调度到线程上执行，仅仅是 runtime\n层面的一个概念，在操作系统之上的层面，操作系统并不能感知到 goroutine 的存在。\u003c/p\u003e\n\u003ch3 id=\"gmp三个基础的结构体来实现-goroutine-的调度\"\u003eG、M、P三个基础的结构体来实现 goroutine 的调度：\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eG 代表一个 goroutine，它包含：表示 goroutine 栈的一些字段，指示当前 goroutine 的状态，指示当前运行到的指令地址，也就是 PC 值。\nM 表示内核线程，包含正在运行的 goroutine 等字段。\nP 代表一个虚拟的CPU Processor，它维护一个处于 Runnable 状态的 goroutine 队列，M 需要获得 P 才能运行 G。\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e当然还有一个核心的结构体：sched，它总揽全局，维持整个调度器的运行。\nRuntime 起始时会启动一些 G：垃圾回收的 G，执行调度的 G，运行用户代码的 G；并且会创建一\n个 M 用来开始 G 的运行。随着时间的推移，G和M的创建数量逐渐增多。\n在 Go 的早期版本，并没有 P 这个结构体，M 必须从一个全局的队列里获取要运行的 G，因此需要获取一个全局的锁，当并发量大的时候，锁就成了瓶颈。后来调度器在 Dmitry Vyukov (Go 语言运行时 runtime 和调度器的核心贡献者之一) ，加\n上了 P 结构体。每个 P 维护一个处于 Runnable 状态的 G 的队列，解决了原来的全局锁问题。\u003c/p\u003e","title":"Go sheduler 是什么?"},{"content":" 内存对齐（Memory Alignment）是计算机系统架构和编程中的一个基本概念，它指的是数据在内存中的存储地址必须是某个值的整数倍。这个“某个值”通常是该数据类型的大小或其最大成员的大小（在结构体中）。\n通过分析以下具体实例加深内存对齐理解。\ntype itab struct { inter *interfacetype // 接口类型信息 _type *_type // 实现接口的具体类型信息 hash uint32 // 类型 hash 值 _ [4]byte fun [1]uintptr // 实现接口方法的函数地址 } 一、Go 的结构体内存布局规则 Go 里每个字段在内存中都有一个偏移量（offset），而编译器会自动插入 padding（填充字节），以保证每个字段都按其类型对齐（alignment）。\n规则大致是： 每个字段的起始地址必须是该字段类型的对齐倍数。 比如：uint32 对齐要求 4 字节，uintptr（在 64 位机上）对齐要求 8 字节。 整个结构体的大小必须是其内部最大对齐单位的整数倍。 编译器自动插入 padding 字节，但有时源码里会显式加 _ [N]byte 来占位或兼容 ABI。\n二、itab 的字段分析（以 64位架构为例） 我们来计算每个字段的内存偏移：\n字段 类型 大小 (Size) 自身对齐值 (Align) 偏移量 (Offset)单位:字节 备注 inter *interfacetype 8 字节 8 字节 0 → 8 8 字节对齐 _type *_type 8 字节 8 字节 8→16 8 是 8 的倍数，已对齐 hash uint32 4 字节 4 字节 16→20 16 是 4 的倍数，已对齐 _ [4]byte 4 字节 1 字节 20→24 4 字节的填充 (Padding) fun [1]uintptr 8 字节 8 字节 24→32 8 字节对齐 24 是 8 的倍数 总大小32 字节，结构体最大对齐是 8 字节，总大小 32 是 8 的倍数。\n三、分析 [4]byte 实现对齐的机制这里的关键是：\n[4]byte 本身不实现对齐，它的存在是作为填充（Padding），从而保证其后续字段 fun 的对齐。 1.目标：fun [1]uintptr 字段是一个 uintptr 数组，在 64 位系统上，uintptr 是 8 字节，所以它必须从一个 8 字节对齐的地址开始。 2.计算： 到 hash 字段结束时，结构体的总大小为 8 + 8 + 4 = 20 字节。 下一个 8 字节对齐的地址是 24 ( 20 之后的第一个 8 的倍数)。 因此，需要在 hash 之后和 fun 之前插入 24 - 20 = 4 字节的填充。 3.实现：Go 源码通过显式地添加一个占位符字段 _ [4]byte 来实现这 4 字节的填充，从而确保 fun [1]uintptr 能够从 24 字节的偏移量开始，完美地实现 8 字节对齐。 四、Go 语言中的字段重排序方法 在 Go 中，重排序字段以实现内存优化的基本原则是：将占用内存空间小的字段（即对齐要求小的字段）放在前面，然后依次放置占用空间大的字段。\n优化规则（降序排列）： 最有效的排序策略是：将结构体中的字段按它们自身大小（即对齐要求）从大到小排列。 字段大小对齐要求 常用类型 优先级 最大 (8 字节) int64, float64, uint64, 指针类型 (*T), string, slice, interface 高 (先放) 中等 (4 字节) int32, float32, uint32 中 最小 (2 字节) int16, uint16 低 最小 (1 字节) bool, int8, uint8, byte 最低 (后放) ","permalink":"https://blog.q-song.top/posts/memory_alignment/","summary":"\u003cblockquote\u003e\n\u003cp\u003e内存对齐（Memory Alignment）是计算机系统架构和编程中的一个基本概念，它指的是数据在内存中的存储地址必须是某个值的整数倍。这个“某个值”通常是该数据类型的大小或其最大成员的大小（在结构体中）。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003e通过分析以下具体实例加深内存对齐理解。\u003c/strong\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003etype itab struct {\n    inter *interfacetype // 接口类型信息\n    _type *_type         // 实现接口的具体类型信息\n    hash  uint32         // 类型 hash 值\n    _     [4]byte\n    fun   [1]uintptr     // 实现接口方法的函数地址\n}\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"一go-的结构体内存布局规则\"\u003e一、Go 的结构体内存布局规则\u003c/h2\u003e\n\u003cp\u003eGo 里每个字段在内存中都有一个偏移量（offset），而编译器会自动插入 padding（填充字节），以保证每个字段都按其类型对齐（alignment）。\u003c/p\u003e\n\u003cp\u003e规则大致是：\n每个字段的起始地址必须是该字段类型的对齐倍数。\n比如：uint32 对齐要求 4 字节，uintptr（在 64 位机上）对齐要求 8 字节。\n整个结构体的大小必须是其内部最大对齐单位的整数倍。\n编译器自动插入 padding 字节，但有时源码里会显式加 _ [N]byte 来占位或兼容 ABI。\u003c/p\u003e\n\u003ch2 id=\"二itab-的字段分析以-64位架构为例\"\u003e二、itab 的字段分析（以 64位架构为例）\u003c/h2\u003e\n\u003cp\u003e我们来计算每个字段的内存偏移：\u003c/p\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: left\"\u003e字段\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e类型\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e大小 (Size)\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e自身对齐值 (Align)\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e偏移量 (Offset)\u003cbr/\u003e单位:字节\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e备注\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003einter\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003e*interfacetype\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e8 字节\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e8 字节\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e0 → 8\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e8 字节对齐\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003e_type\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003e*_type\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e8 字节\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e8 字节\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e8→16\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e8  是  8  的倍数，已对齐\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003ehash\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003euint32\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e4 字节\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e4 字节\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e16→20\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e16  是  4  的倍数，已对齐\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003e_\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003e[4]byte\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e4 字节\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e1 字节\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e20→24\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e4 字节的填充 (Padding)\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003efun\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e\u003ccode\u003e[1]uintptr\u003c/code\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e8 字节\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e8 字节\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e24→32\u003c/td\u003e\n          \u003ctd style=\"text-align: left\"\u003e8 字节对齐  24  是  8  的倍数\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e总大小32 字节，结构体最大对齐是 8 字节，总大小 32 是 8 的倍数。\u003c/p\u003e","title":"内存对齐（memory alignment）"},{"content":" 主键（Primary Key）是唯一标识每行的非空字段，每表只能有一个； 唯一键（Unique Key）是保证字段值唯一，但允许为NULL，每表可有多个。\n主键 (Primary Key) 定义：用于唯一标识表中每一行数据的字段或字段组合，是表的核心标识。 作用：为其他表提供关联引用的核心字段，唯一标识表中的每一行数据。 特点 唯一性：所有主键值必须唯一，不可重复。 非空性：主键字段禁止为 NULL。 单例性：每张表仅能定义一个主键（但可以是多字段的联合主键）。 索引支持：数据库一般会为主键自动创建索引来提高查询效率。\n唯一键 (Unique Key) 定义：用于确保字段或字段组合的值唯一，但非表的唯一标识。 作用：提供辅助的唯一性约束，便于业务逻辑使用。确保指定列或列组合在表中的数据唯一，防止重复数据产生。 特点 唯一性：字段值不可重复，但允许 NULL，具体可允许多少个 NULL，取决于数据库实现，如 MySQL 可以有多个。 多例性：一张表可定义多个唯一键，用来约束不同的业务属性。 索引支持：数据库也通常会为唯一键创建索引，提高检索速度。\n主要区别 数量限制 主键：每张表只能有一个。 唯一键：一张表可以定义多个。\n用途侧重 主键：这一列（或列组合）在逻辑上就是记录的“身份证”，最常用来建立实体与实体间的关联。 唯一键：更多是防止重复数据，保证业务字段（如邮箱、手机号等）具有唯一性，但并非必然用作数据行的主标识。\n约束规则 主键：强制非空（NOT NULL），插入数据时必须显式指定值，但若设置 AUTO_INCREMENT，MySQL 会自动分配下一个可用值。插入后通常不推荐更新主键值。 唯一键：允许 NULL 值，例如：MySQL允许多个 NULL视为不冲突而SQL Server仅允许一个 NULL。值可更新，但需保证新值唯一。\n索引与性能 主键：默认创建聚集索引（如 MySQL InnoDB 、SQL Server），物理上按主键顺序存储数据，范围查询非常高效。 唯一键：默认创建非聚集索引，逻辑上维护唯一性，适合等值查询。\n简单示例 主键场景：在“用户表”中，UserID 作为主键，保证每位用户都能被独一无二地识别和引用。 唯一键场景：在同一个用户表中，Email 字段也要求不能重复时，就可以为 Email 设置唯一键；此时允许它为 NULL，但实际业务上通常会要求非 NULL 并且唯一。 总结\n主键和唯一键都用于保证数据唯一性，但主键更侧重于表的标识和引用，而唯一键更侧重于业务属性的唯一性约束。在实际应用中，通常会结合使用两者来实现数据完整性和业务规则的约束。\n主键其实就是用来标识每行数据身份的核心字段或字段组合，必须保证主键值的非空性和唯一性。非空性是指插入主键值数据时必须显式指定值，但如果设置了自增（AUTO_INCREMENT），插入数据时就不用手动指定值，数据库会自动分配下一个可用的数值，另外通常不建议在插入后再去修改主键。唯一性是指主键值数据整能够唯一标识表中的一行，此外数据库一般会自动给它创建聚簇索引。 相比之下，唯一键虽然也要保证相应字段的值的唯一性，但它更偏向业务层面的唯一性控制，不一定要当成每行数据的主识别字段。它允许为空，而且在不同的数据库里，对空值的处理也不一样，有的可以插入多个空值，例如MySQL。有的只能插一次，例如SQL Server 。一个表中可以同时存在多个唯一键，每个唯一键都会有对应的非聚簇索引来提升检索效率，这样就能在业务里确保不同属性都能做到唯一。 两者主要区别，首先是每张表只能有一个主键，但可以有多个唯一键。 其次是主键一定不能为空，而唯一键通常允许空值。 还有，主键往往是用来跟别的表建立关联，比如用户表中的 UserID 作为主键，就能让其他表引用这个字段来关联用户信息。唯一键更多是防止个别业务字段的重复，比如用户表中的 Email 地址如果也要求唯一，可以设置成唯一键，这样就能保证任何两个用户都不会用到相同的邮箱。 最后，数据库在主键和唯一键上也有不同的索引方式，InnoDB 或 SQL Server 的主键会采用聚集索引，让物理存储和主键顺序相关联，范围查询时会更高效；而唯一键通常是非聚集索引，比较侧重等值查询。 总之，主键和唯一键都用于保证数据唯一性，但主键更侧重于表的标识和引用，而唯一键更侧重于业务属性的唯一性约束。在实际应用中，通常会结合使用两者来实现数据完整性和业务规则的约束。 ","permalink":"https://blog.q-song.top/posts/sql_key/","summary":"\u003cblockquote\u003e\n\u003cp\u003e主键（Primary Key）是唯一标识每行的非空字段，每表只能有一个；\n唯一键（Unique Key）是保证字段值唯一，但允许为NULL，每表可有多个。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"主键-primary-key\"\u003e主键 (Primary Key)\u003c/h2\u003e\n\u003ch5 id=\"定义用于唯一标识表中每一行数据的字段或字段组合是表的核心标识\"\u003e定义：用于唯一标识表中每一行数据的字段或字段组合，是表的核心标识。\u003c/h5\u003e\n\u003ch5 id=\"作用为其他表提供关联引用的核心字段唯一标识表中的每一行数据\"\u003e作用：为其他表提供关联引用的核心字段，唯一标识表中的每一行数据。\u003c/h5\u003e\n\u003ch5 id=\"特点\"\u003e特点\u003c/h5\u003e\n\u003cp\u003e唯一性：所有主键值必须唯一，不可重复。\n非空性：主键字段禁止为 NULL。\n单例性：每张表仅能定义一个主键（但可以是多字段的联合主键）。\n索引支持：数据库一般会为主键自动创建索引来提高查询效率。\u003c/p\u003e\n\u003ch2 id=\"唯一键-unique-key\"\u003e唯一键 (Unique Key)\u003c/h2\u003e\n\u003ch5 id=\"定义用于确保字段或字段组合的值唯一但非表的唯一标识\"\u003e定义：用于确保字段或字段组合的值唯一，但非表的唯一标识。\u003c/h5\u003e\n\u003ch5 id=\"作用提供辅助的唯一性约束便于业务逻辑使用确保指定列或列组合在表中的数据唯一防止重复数据产生\"\u003e作用：提供辅助的唯一性约束，便于业务逻辑使用。确保指定列或列组合在表中的数据唯一，防止重复数据产生。\u003c/h5\u003e\n\u003ch5 id=\"特点-1\"\u003e特点\u003c/h5\u003e\n\u003cp\u003e唯一性：字段值不可重复，但允许 NULL，具体可允许多少个 NULL，取决于数据库实现，如 MySQL 可以有多个。\n多例性：一张表可定义多个唯一键，用来约束不同的业务属性。\n索引支持：数据库也通常会为唯一键创建索引，提高检索速度。\u003c/p\u003e\n\u003ch2 id=\"主要区别\"\u003e主要区别\u003c/h2\u003e\n\u003ch5 id=\"数量限制\"\u003e数量限制\u003c/h5\u003e\n\u003cp\u003e主键：每张表只能有一个。\n唯一键：一张表可以定义多个。\u003c/p\u003e\n\u003ch5 id=\"用途侧重\"\u003e用途侧重\u003c/h5\u003e\n\u003cp\u003e主键：这一列（或列组合）在逻辑上就是记录的“身份证”，最常用来建立实体与实体间的关联。\n唯一键：更多是防止重复数据，保证业务字段（如邮箱、手机号等）具有唯一性，但并非必然用作数据行的主标识。\u003c/p\u003e\n\u003ch5 id=\"约束规则\"\u003e约束规则\u003c/h5\u003e\n\u003cp\u003e主键：强制非空（NOT NULL），插入数据时必须显式指定值，但若设置 AUTO_INCREMENT，MySQL 会自动分配下一个可用值。插入后通常不推荐更新主键值。\n唯一键：允许 NULL 值，例如：MySQL允许多个 NULL视为不冲突而SQL Server仅允许一个 NULL。值可更新，但需保证新值唯一。\u003c/p\u003e\n\u003ch5 id=\"索引与性能\"\u003e索引与性能\u003c/h5\u003e\n\u003cp\u003e主键：默认创建聚集索引（如 MySQL InnoDB 、SQL Server），物理上按主键顺序存储数据，范围查询非常高效。\n唯一键：默认创建非聚集索引，逻辑上维护唯一性，适合等值查询。\u003c/p\u003e\n\u003ch2 id=\"简单示例\"\u003e简单示例\u003c/h2\u003e\n\u003cp\u003e主键场景：在“用户表”中，UserID 作为主键，保证每位用户都能被独一无二地识别和引用。\n唯一键场景：在同一个用户表中，Email 字段也要求不能重复时，就可以为 Email 设置唯一键；此时允许它为 NULL，但实际业务上通常会要求非 NULL 并且唯一。\n总结\u003c/p\u003e\n\u003cp\u003e主键和唯一键都用于保证数据唯一性，但主键更侧重于表的标识和引用，而唯一键更侧重于业务属性的唯一性约束。在实际应用中，通常会结合使用两者来实现数据完整性和业务规则的约束。\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e主键其实就是用来标识每行数据身份的核心字段或字段组合，必须保证主键值的非空性和唯一性。非空性是指插入主键值数据时必须显式指定值，但如果设置了自增（AUTO_INCREMENT），插入数据时就不用手动指定值，数据库会自动分配下一个可用的数值，另外通常不建议在插入后再去修改主键。唯一性是指主键值数据整能够唯一标识表中的一行，此外数据库一般会自动给它创建聚簇索引。\n\n相比之下，唯一键虽然也要保证相应字段的值的唯一性，但它更偏向业务层面的唯一性控制，不一定要当成每行数据的主识别字段。它允许为空，而且在不同的数据库里，对空值的处理也不一样，有的可以插入多个空值，例如MySQL。有的只能插一次，例如SQL Server 。一个表中可以同时存在多个唯一键，每个唯一键都会有对应的非聚簇索引来提升检索效率，这样就能在业务里确保不同属性都能做到唯一。\n\n两者主要区别，首先是每张表只能有一个主键，但可以有多个唯一键。\n\n其次是主键一定不能为空，而唯一键通常允许空值。\n\n还有，主键往往是用来跟别的表建立关联，比如用户表中的 UserID 作为主键，就能让其他表引用这个字段来关联用户信息。唯一键更多是防止个别业务字段的重复，比如用户表中的 Email 地址如果也要求唯一，可以设置成唯一键，这样就能保证任何两个用户都不会用到相同的邮箱。\n\n最后，数据库在主键和唯一键上也有不同的索引方式，InnoDB 或 SQL Server 的主键会采用聚集索引，让物理存储和主键顺序相关联，范围查询时会更高效；而唯一键通常是非聚集索引，比较侧重等值查询。\n\n总之，主键和唯一键都用于保证数据唯一性，但主键更侧重于表的标识和引用，而唯一键更侧重于业务属性的唯一性约束。在实际应用中，通常会结合使用两者来实现数据完整性和业务规则的约束。\n\u003c/code\u003e\u003c/pre\u003e","title":"主键和唯一键？区别是什么？"},{"content":" 在 Go 后端开发中，我们通常使用 MySQL 或 PostgreSQL 等关系型数据库，索引设计的好坏直接决定了服务接口的响应速度。\n1.索引设计 1.1 选择合适的列作为索引： 选择性高（High Selectivity）： 索引列的不重复值越多越好。例如，用户 ID（唯一）比性别（只有两三种值）更适合作为索引。 场景： 在设计用户服务时，user_id、email 等是理想的索引列。 常用作查询条件（Where）： 经常出现在 WHERE 子句中的列，或者用于连接（JOIN）的列。 排序/分组（Order By/Group By）： 经常用于排序或分组的列。 1.2 考虑联合索引（Composite Index）： 最左前缀原则 (Leftmost Prefix Principle)： 这是联合索引设计的核心。如果创建了 (A, B, C) 的联合索引，它可以用于查询 WHERE A = ?、WHERE A = ? AND B = ?、WHERE A = ? AND B = ? AND C = ?，但不能单独用于 WHERE B = ? 或 WHERE C = ?。 场景： 在设计订单查询接口时，如果经常查询 WHERE user_id = ? AND order_status = ?，应建立 (user_id, order_status) 的联合索引。 1.3 覆盖索引 (Covering Index)： 如果查询的所有字段都包含在索引中，那么数据库不需要回表（查找主键对应的数据行），直接从索引中返回数据即可。这能大幅提升性能。 场景： 当你需要查询某个用户的订单状态和创建时间，只创建 (user_id, status, create_time) 的联合索引。查询语句为 SELECT status, create_time FROM orders WHERE user_id = ?，数据库直接通过索引就能拿到结果。 1.4 索引数量的平衡： 索引不是越多越好。每个索引都会占用磁盘空间，并且在进行 INSERT, UPDATE, DELETE 操作时，数据库需要维护索引，造成写操作性能下降。 场景： 在设计高写入量的日志表或消息表时，应尽量少建索引，只保留用于最核心查询的索引。 2.高效命中策略 使用 Explain ： 在 Go 后端进行复杂查询优化时，一定要在测试环境使用 EXPLAIN 命令分析 SQL 语句，确保 type 列不是 ALL（全表扫描），key 列使用了正确的索引。\nGo 代码中遵循 最左前缀原则 ： 确保在 Go 代码中构造查询条件时，联合索引的最左侧列总是被包含。\n// 假设索引为 (user_id, status, created_at) // 高效命中：查询中包含 user_id db.Where(\u0026#34;user_id = ? AND status = ?\u0026#34;, userID, status).Find(\u0026amp;orders) // 命中索引的前缀 (user_id)：虽然没有 status，但仍然高效。 db.Where(\u0026#34;user_id = ?\u0026#34;, userID).Find(\u0026amp;orders) // 低效/索引失效：查询中不包含 user_id db.Where(\u0026#34;status = ?\u0026#34;, status).Find(\u0026amp;orders) // 仅 status 无法利用联合索引 // 3.导致索引失效 3.1 导致索引失效的常见方式 索引失效意味着查询优化器放弃使用索引，转而进行全表扫描（ALL），这是后端服务产生慢查询的主要原因。\n失效方式 示例 SQL 为什么失效？ Go 后端实践建议 对索引列进行函数操作 WHERE YEAR(create_time) = 2024 数据库需要对每一行的 create_time 执行 YEAR() 函数，无法直接通过索引 B+ Tree 结构查找。 应将函数操作放在等号右侧：\nWHERE create_time \u0026gt;= '2024-01-01' AND create_time \u0026lt; '2025-01-01' LIKE 模糊查询开头 WHERE username LIKE '%zhangsan' 百分号 % 在左侧，导致无法利用 B+ Tree 的有序性进行快速查找。 尽量使用前缀匹配：\nWHERE username LIKE 'zhangsan%'。如果必须使用左模糊，考虑使用 Elasticsearch 或其他全文检索方案。 类型转换（隐式转换） WHERE phone = 13800001111（phone 字段是 VARCHAR） 字符串字段和数字进行比较，MySQL 会将字符串隐式转换为数字，相当于对索引列进行了函数操作。 在 Go 代码中严格控制数据类型，使用字符串参数进行查询：\ndb.Where(\u0026quot;phone = ?\u0026quot;, \u0026quot;13800001111\u0026quot;)。 使用 OR 连接条件 WHERE name = 'A' OR age = 18 如果 name 和 age 字段都没有索引或索引类型不匹配，优化器倾向于全表扫描。 如果两个列都有索引，有时会采用索引合并；但更推荐将 OR 拆分为两个 UNION 查询。 违反最左前缀原则 联合索引 (A, B, C)，查询 WHERE B = ? AND C = ? 跳过联合索引的最左侧列 A，B+ Tree 无法按顺序查找。 检查联合索引的设计和查询语句，确保查询条件涵盖联合索引的左侧列。 使用负向查询 WHERE status != 0 或 WHERE col NOT IN (1, 2) 负向查询覆盖了大部分数据，优化器认为全表扫描更快。 尽量使用正向查询：\nWHERE status IN (1, 2, 3)。 ","permalink":"https://blog.q-song.top/posts/sql_index/","summary":"\u003cblockquote\u003e\n\u003cp\u003e在 Go 后端开发中，我们通常使用 MySQL 或 PostgreSQL 等关系型数据库，索引设计的好坏直接决定了服务接口的响应速度。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"1索引设计\"\u003e1.索引设计\u003c/h3\u003e\n\u003ch4 id=\"11-选择合适的列作为索引\"\u003e1.1 选择合适的列作为索引：\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e选择性高（High Selectivity）： 索引列的不重复值越多越好。例如，用户 ID（唯一）比性别（只有两三种值）更适合作为索引。\n场景： 在设计用户服务时，user_id、email 等是理想的索引列。\n常用作查询条件（Where）： 经常出现在 WHERE 子句中的列，或者用于连接（JOIN）的列。\n排序/分组（Order By/Group By）： 经常用于排序或分组的列。\n\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"12-考虑联合索引composite-index\"\u003e1.2 考虑联合索引（Composite Index）：\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e最左前缀原则 (Leftmost Prefix Principle)： 这是联合索引设计的核心。如果创建了 (A, B, C) 的联合索引，它可以用于查询 WHERE A = ?、WHERE A = ? AND B = ?、WHERE A = ? AND B = ? AND C = ?，但不能单独用于 WHERE B = ? 或 WHERE C = ?。\n场景： 在设计订单查询接口时，如果经常查询 WHERE user_id = ? AND order_status = ?，应建立 (user_id, order_status) 的联合索引。\n\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"13-覆盖索引-covering-index\"\u003e1.3 覆盖索引 (Covering Index)：\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e如果查询的所有字段都包含在索引中，那么数据库不需要回表（查找主键对应的数据行），直接从索引中返回数据即可。这能大幅提升性能。\n场景： 当你需要查询某个用户的订单状态和创建时间，只创建 (user_id, status, create_time) 的联合索引。查询语句为 SELECT status, create_time FROM orders WHERE user_id = ?，数据库直接通过索引就能拿到结果。\n\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"14-索引数量的平衡\"\u003e1.4 索引数量的平衡：\u003c/h4\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e索引不是越多越好。每个索引都会占用磁盘空间，并且在进行 INSERT, UPDATE, DELETE 操作时，数据库需要维护索引，造成写操作性能下降。\n场景： 在设计高写入量的日志表或消息表时，应尽量少建索引，只保留用于最核心查询的索引。\n\u003c/code\u003e\u003c/pre\u003e\u003chr\u003e\n\u003ch3 id=\"2高效命中策略\"\u003e2.高效命中策略\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e使用 Explain ： 在 Go 后端进行复杂查询优化时，一定要在测试环境使用 EXPLAIN 命令分析 SQL 语句，确保 type 列不是 ALL（全表扫描），key 列使用了正确的索引。\u003c/strong\u003e\u003c/p\u003e","title":"SQL_Index 索引"},{"content":" Go 语言里 slice 和 map 是非常有用的两个内置数据结构， 线上的工程代码几乎不可能绕开它们。\n1.数组与切片 因为切片（slice）比数组更好用，也更安全，Go 推荐使用 slice 而不是数组。本节内容比较 了 slice 和数组的区别，也研究了 slice 的一些特有的性质。\n1.1数组和切片有何异同 Go 语言中的切片（slice）结构的本质是对数组的封装，它描述一个数组的片段。无论是数组 还是切片，都可以通过下标来访问单个元素。 数组是定长的，长度定义好之后，不能再更改。在 Go 语言中，数组是不常见的，因为其长度 是类型的一部分，限制了它的表达能力，比如 [3]int 和 [4]int 就是不同的类型。而切片则非常灵 活，它可以动态地扩容，且切片的类型和长度无关。\nfunc main() { arr1 := [1]int{1} arr2 := [2]int{1, 2} if arr1 == arr2 { fmt.Println(\u0026quot;equal type\u0026quot;) } } 尝试运行，报编译错误：\n./test.go:16:10: invalid operation: arr1 == arr2 (mismatched types [1]int and [2]int) 因为两个数组的长度不同，根本就不是同一类型，因此不能进行比较。 数组是一片连续的内存，切片实际上是一个结构体，包含三个字段：长度、容量、底层数组。\n// src/runtime/slice.go type slice struct { array unsafe.Pointer // 元素指针 len int // 长度 cap int // 容量 } 注意，底层数组可以被多个切片同时指向，因此对一个切 片的元素进行操作有可能会影响到其他切片。\n1.2切片如何被截取 截取也是一种比较常见的创建 slice 的方法，可以从数组或者 slice 直接截取，需要指定起、 止索引位置。 基于已有 slice 创建新 slice 对象，被称为 reslice。新 slice 和老 slice 共用底层数组，新老 slice 对底层数组的更改都会影响到彼此。基于数组创建的新 slice 也是同样的效果：对数组或 slice 元素做的更改都会影响到彼此。 值得注意的是，新老 slice 或者新 slice 老数组互相影响的前提是两者共用底层数组，如果因 为执行 append 操作使得新 slice 或老 slice 底层数组扩容，移动到了新的位置，两者就不会相互影 响了。所以，问题的关键在于两者是否会共用底层数组。\ndata := [...]int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9} slice := data[2:4:6] // data[low, high, max 对 data 使用 3 个索引值，截取出新的 slice。这里 data 可以是数组或者 slice。low 是最低索引 值，这里是闭区间，也就是说第一个元素是 data 位于 low 索引处的元素；而 high 和 max 则是开区 间，表示最后一个元素只能是索引 high-1 处的元素，而最大容量则只能是索引 max-1 处的元素。 要求：max \u0026gt;= high \u0026gt;= low 当 high == low 时，新 slice 为空。\n","permalink":"https://blog.q-song.top/posts/slice_01/","summary":"\u003cblockquote\u003e\n\u003cp\u003eGo 语言里 slice 和 map 是非常有用的两个内置数据结构，\n线上的工程代码几乎不可能绕开它们。\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"1数组与切片\"\u003e1.数组与切片\u003c/h3\u003e\n\u003cp\u003e因为切片（slice）比数组更好用，也更安全，Go 推荐使用 slice 而不是数组。本节内容比较\n了 slice 和数组的区别，也研究了 slice 的一些特有的性质。\u003c/p\u003e\n\u003ch4 id=\"11数组和切片有何异同\"\u003e1.1数组和切片有何异同\u003c/h4\u003e\n\u003cp\u003eGo 语言中的切片（slice）结构的本质是对数组的封装，它描述一个数组的片段。无论是数组\n还是切片，都可以通过下标来访问单个元素。\n数组是定长的，长度定义好之后，不能再更改。在 Go 语言中，数组是不常见的，因为其长度\n是类型的一部分，限制了它的表达能力，比如 [3]int 和 [4]int 就是不同的类型。而切片则非常灵\n活，它可以动态地扩容，且切片的类型和长度无关。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003efunc main() { \n    arr1 := [1]int{1}\n    arr2 := [2]int{1, 2}\n    if arr1 == arr2 {\n    fmt.Println(\u0026quot;equal type\u0026quot;)\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e尝试运行，报编译错误：\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e./test.go:16:10: invalid operation: arr1 == arr2 (mismatched types [1]int and [2]int)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e因为两个数组的长度不同，根本就不是同一类型，因此不能进行比较。\n数组是一片连续的内存，切片实际上是一个结构体，包含三个字段：长度、容量、底层数组。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e// src/runtime/slice.go\n    type slice struct {\n    array unsafe.Pointer // 元素指针\n    len int // 长度\n    cap int // 容量\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e注意，底层数组可以被多个切片同时指向，因此对一个切\n片的元素进行操作有可能会影响到其他切片。\u003c/p\u003e","title":"slice 和 数组"},{"content":"今天开始记录我在 Go 高并发项目中的一些心得体会。\n","permalink":"https://blog.q-song.top/posts/fist-blog/","summary":"\u003cp\u003e今天开始记录我在 Go 高并发项目中的一些心得体会。\u003c/p\u003e","title":"我的第一篇博客"},{"content":"🚀 什么是 Hugo？ Hugo 是一个基于 Go 语言编写的 静态网站生成器。\n它的最大特点是——速度极快、部署方便、几乎零依赖。\n使用 Hugo，你可以用 Markdown 写文章，然后自动生成一个完整的博客网站。\n🛠️ 安装 Hugo 在 macOS 上：\nbrew install hugo ","permalink":"https://blog.q-song.top/posts/%E5%88%9D%E8%AF%86-hugo%E6%89%93%E9%80%A0%E4%BD%A0%E7%9A%84%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2/","summary":"\u003ch2 id=\"-什么是-hugo\"\u003e🚀 什么是 Hugo？\u003c/h2\u003e\n\u003cp\u003eHugo 是一个基于 Go 语言编写的 \u003cstrong\u003e静态网站生成器\u003c/strong\u003e。\u003cbr\u003e\n它的最大特点是——\u003cstrong\u003e速度极快、部署方便、几乎零依赖\u003c/strong\u003e。\u003c/p\u003e\n\u003cp\u003e使用 Hugo，你可以用 Markdown 写文章，然后自动生成一个完整的博客网站。\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"-安装-hugo\"\u003e🛠️ 安装 Hugo\u003c/h2\u003e\n\u003cp\u003e在 macOS 上：\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ebrew install hugo\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e","title":"First Encounter with Hugo"},{"content":" 电商购物平台 \u0026amp; 管理后台（Go + Iris + MySQL + Redis + RabbitMQ + Nginx）\n前后端一体化 Web 项目，从前端 UI、后端接口、数据库设计到上线部署。 这是我从零开始独立完成的完整的前后端一体化Web项目，从前端UI、后端接口、数据库设计到上线部署，都是自己亲手实现。 项目的目标是构建一个完整的电商流程：商品浏览、分类展示、购物车、订单流程，以及后台的商品管理、订单管理、用户管理等。 用户端界面展示 “宇宙购物”（SPACE SHOPPING）的电商平台，整体风格现代、简洁、实用。\n瀑布流布局 \u0026amp; 搜索栏\n商品分类导航(多级导航栏)\n商品详情(加入购物车、立即抢购)\n高性能排行榜单\n用户下单(确认和生成订单)\n页面的 UI 风格参考了大型电商平台（如淘宝、京东）的布局结构，整体结构清晰，视觉优雅。\n管理后台系统 后台系统提供api管理全站信息，是自己设计的简洁的CMS管理平台。\n订单管理 商品管理 支持新增、编辑、删除商品，上传图片，设置库存、分类等。\n商品分类管理 查看商品分类明细和支持新增、编辑、删除等操作\n用户管理 查看用户列表、状态，支持冻结/启用。\n管理员管理 查看管理员列表、状态，支持冻结/启用。\n技术栈 前端： HTML + CSS + JS 部分页面使用 Vue 简化动态逻辑 管理后台基于 Admin 模板自定义开发 后端： Go（Golang） Iris Web 框架 MySQL（核心数据） + Redis（缓存 \u0026amp; session） JWT 登录认证 RabbitMQ（异步消息） Nginx（反向代理） 部署： Ubuntu Server systemd 服务托管（自动重启、日志收集） Nginx 反代 / 静态资源服务 二进制打包发布，软链接切换版本（current → eshop_v2） 项目亮点 支持高并发的基础架构搭建 项目内集成了： Redis 缓存 RabbitMQ 消息队列 Nginx 负载均衡预留接口 为将来扩展秒杀、异步通知等功能做了铺垫。 碎碎念 哈哈当然啦，在开发的整个过程还是有许多收获的。 例如加深对Go语言的熟悉程度、各种中间件和相互之间的如何应用、如何构建一个高可靠和高可用的系统、 在高并发条件下如何容错、如何解决数据可能丢失和学会排查系统错误、端口冲突、模板路径问题等等。 也许在不久还会有更多出色的应用，敬请期待吧~ ","permalink":"https://blog.q-song.top/posts/my_project01/","summary":"\u003ch3\u003e\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e电商购物平台 \u0026amp; 管理后台（Go + Iris + MySQL + Redis + RabbitMQ + Nginx）\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"前后端一体化-web-项目从前端-ui后端接口数据库设计到上线部署\"\u003e前后端一体化 Web 项目，从前端 UI、后端接口、数据库设计到上线部署。\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e这是我从零开始独立完成的完整的前后端一体化Web项目，从前端UI、后端接口、数据库设计到上线部署，都是自己亲手实现。\u003c/li\u003e\n\u003cli\u003e项目的目标是构建一个完整的电商流程：商品浏览、分类展示、购物车、订单流程，以及后台的商品管理、订单管理、用户管理等。\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"用户端界面展示\"\u003e用户端界面展示\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003e “宇宙购物”（SPACE SHOPPING）的电商平台，整体风格现代、简洁、实用。\u003c/code\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e瀑布流布局 \u0026amp; 搜索栏\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/my_project01/%E9%A6%96%E9%A1%B5.png\"\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e商品分类导航(多级导航栏)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/my_project01/%E5%95%86%E5%93%81%E5%88%86%E7%B1%BB%E5%AF%BC%E8%88%AA.png\"\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e商品详情(加入购物车、立即抢购)\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/my_project01/%E5%95%86%E5%93%81%E8%AF%A6%E6%83%85.png\"\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e高性能排行榜单\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/my_project01/%E9%AB%98%E6%80%A7%E8%83%BD%E6%8E%92%E8%A1%8C%E6%A6%9C%E5%8D%95.png\"\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e用户下单(确认和生成订单)\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e 页面的 UI 风格参考了大型电商平台（如淘宝、京东）的布局结构，整体结构清晰，视觉优雅。\u003c/code\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/my_project01/%E7%94%A8%E6%88%B7%E4%B8%8B%E5%8D%95.png\"\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/posts/my_project01/%E6%88%90%E5%8A%9F%E4%B8%8B%E5%8D%95.png\"\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"管理后台系统\"\u003e管理后台系统\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003e后台系统提供api管理全站信息，是自己设计的简洁的CMS管理平台。\u003c/code\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e订单管理\u003c/li\u003e\n\u003cli\u003e\u003cimg loading=\"lazy\" src=\"/posts/my_project01/%E8%AE%A2%E5%8D%95%E7%AE%A1%E7%90%86.png\"\u003e\u003c/li\u003e\n\u003cli\u003e商品管理\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003ccode\u003e支持新增、编辑、删除商品，上传图片，设置库存、分类等。\u003c/code\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cimg loading=\"lazy\" src=\"/posts/my_project01/%E5%95%86%E5%93%81%E7%AE%A1%E7%90%86.png\"\u003e\u003c/li\u003e\n\u003cli\u003e商品分类管理\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003ccode\u003e查看商品分类明细和支持新增、编辑、删除等操作\u003c/code\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cimg loading=\"lazy\" src=\"/posts/my_project01/%E5%88%86%E7%B1%BB%E7%AE%A1%E7%90%86.png\"\u003e\u003c/li\u003e\n\u003cli\u003e用户管理\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003ccode\u003e查看用户列表、状态，支持冻结/启用。\u003c/code\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e管理员管理\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003ccode\u003e查看管理员列表、状态，支持冻结/启用。\u003c/code\u003e\u003c/p\u003e\n\u003ch3 id=\"技术栈\"\u003e技术栈\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e前端：\nHTML + CSS + JS\n部分页面使用 Vue 简化动态逻辑\n管理后台基于 Admin 模板自定义开发\n\n后端：\nGo（Golang）\nIris Web 框架\nMySQL（核心数据） + Redis（缓存 \u0026amp; session）\nJWT 登录认证\nRabbitMQ（异步消息）\nNginx（反向代理）\n\n部署：\nUbuntu Server\nsystemd 服务托管（自动重启、日志收集）\nNginx 反代 / 静态资源服务\n二进制打包发布，软链接切换版本（current → eshop_v2）\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"项目亮点\"\u003e项目亮点\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e支持高并发的基础架构搭建\n项目内集成了：\nRedis 缓存\nRabbitMQ 消息队列\nNginx 负载均衡预留接口\n为将来扩展秒杀、异步通知等功能做了铺垫。\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"碎碎念\"\u003e碎碎念\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e哈哈当然啦，在开发的整个过程还是有许多收获的。\n例如加深对Go语言的熟悉程度、各种中间件和相互之间的如何应用、如何构建一个高可靠和高可用的系统、\n在高并发条件下如何容错、如何解决数据可能丢失和学会排查系统错误、端口冲突、模板路径问题等等。\n也许在不久还会有更多出色的应用，敬请期待吧~\n\u003c/code\u003e\u003c/pre\u003e","title":"我的项目"}]